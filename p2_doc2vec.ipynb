{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting testfixtures\n",
      "  Using cached https://files.pythonhosted.org/packages/39/ac/a2d5b0e8f25696b292b52fa4f54e36f51db83c5ad07aca4883501b198015/testfixtures-6.10.3-py2.py3-none-any.whl\n",
      "Installing collected packages: testfixtures\n",
      "Successfully installed testfixtures-6.10.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install testfixtures --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A Reimplication of the 'Paragraph Vector' paper\n",
    "==============================================================\n",
    "\n",
    "Shows how to reproduce results of the \"Distributed Representation of Sentences and Documents\" paper by Le and Mikolov using Gensim.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "------------\n",
    "\n",
    "This guide shows you how to reproduce the results of the paper by `Le and\n",
    "Mikolov 2014 <https://arxiv.org/pdf/1405.4053.pdf>`_ using Gensim. While the\n",
    "entire paper is worth reading (it's only 9 pages), we will be focusing on\n",
    "Section 3.2: \"Beyond One Sentence - Sentiment Analysis with the IMDB\n",
    "dataset\".\n",
    "\n",
    "\n",
    "Load corpus\n",
    "-----------\n",
    "\n",
    "Our data for the tutorial will be the `IMDB archive\n",
    "<http://ai.stanford.edu/~amaas/data/sentiment/>`_.\n",
    "If you're not familiar with this dataset, then here's a brief intro: it\n",
    "contains several thousand movie reviews.\n",
    "\n",
    "Each review is a single line of text containing multiple sentences, for example:\n",
    "\n",
    "```\n",
    "One of the best movie-dramas I have ever seen. We do a lot of acting in the\n",
    "church and this is one that can be used as a resource that highlights all the\n",
    "good things that actors can do in their work. I highly recommend this one,\n",
    "especially for those who have an interest in acting, as a \"must see.\"\n",
    "```\n",
    "\n",
    "These reviews will be the **documents** that we will work with in this tutorial.\n",
    "There are 100 thousand reviews in total.\n",
    "\n",
    "#. 25k reviews for training (12.5k positive, 12.5k negative)\n",
    "#. 25k reviews for testing (12.5k positive, 12.5k negative)\n",
    "#. 50k unlabeled reviews\n",
    "\n",
    "Out of 100k reviews, 50k have a label: either positive (the reviewer liked\n",
    "the movie) or negative.\n",
    "The remaining 50k are unlabeled.\n",
    "\n",
    "Our first task will be to prepare the dataset.\n",
    "\n",
    "\n",
    "\n",
    "First, let's define a convenient datatype for holding data for a single document:\n",
    "\n",
    "* words: The text of the document, as a ``list`` of words.\n",
    "* tags: Used to keep the index of the document in the entire dataset.---document tags not sentiment labels\n",
    "* split: one of ``train``\\ , ``test`` or ``extra``. Determines how the document will be used (for training, testing, etc).\n",
    "* sentiment: either 1 (positive), 0 (negative) or None (unlabeled document).\n",
    "\n",
    "This data type is helpful for later evaluation and reporting.\n",
    "In particular, the ``index`` member will help us quickly and easily retrieve the vectors for a document from a model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "SentimentDocument = collections.namedtuple('SentimentDocument', 'words tags split sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed with loading the corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "import smart_open\n",
    "import gensim.utils\n",
    "\n",
    "# def download_dataset(url='http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'):\n",
    "#     fname = url.split('/')[-1]\n",
    "\n",
    "#     if os.path.isfile(fname):\n",
    "#        return fname\n",
    "\n",
    "#     # Download the file to local storage first.\n",
    "#     # We can't read it on the fly because of\n",
    "#     # https://github.com/RaRe-Technologies/smart_open/issues/331\n",
    "#     with smart_open.open(url, \"rb\", ignore_ext=True) as fin:\n",
    "#         with smart_open.open(fname, 'wb', ignore_ext=True) as fout:\n",
    "#             while True:\n",
    "#                 buf = fin.read(io.DEFAULT_BUFFER_SIZE)\n",
    "#                 if not buf:\n",
    "#                     break\n",
    "#                 fout.write(buf)\n",
    "\n",
    "#     return fname\n",
    "fname = 'aclImdb_v1.tar.gz'\n",
    "\n",
    "def create_sentiment_document(name, text, index):\n",
    "    _, split, sentiment_str, _ = name.split('/')\n",
    "    sentiment = {'pos': 1.0, 'neg': 0.0, 'unsup': None}[sentiment_str]\n",
    "\n",
    "    if sentiment is None:\n",
    "        split = 'extra'\n",
    "\n",
    "    tokens = gensim.utils.to_unicode(text).split()\n",
    "    return SentimentDocument(tokens, [index], split, sentiment)\n",
    "\n",
    "def extract_documents():\n",
    "    index = 0\n",
    "    \n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "#             print(member.name)\n",
    "            if re.match(r'aclImdb/(train|test)/(pos|neg|unsup)/\\d+_\\d+.txt$', member.name):\n",
    "                member_bytes = tar.extractfile(member).read()\n",
    "                member_text = member_bytes.decode('utf-8', errors='replace')\n",
    "                assert member_text.count('\\n') == 0\n",
    "                yield create_sentiment_document(member.name, member_text, index)\n",
    "                index += 1\n",
    "                \n",
    "alldocs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the p1's dataset, and use 10% round-robin cv list for test here. That's 200 reviews in total\n",
    "'''\n",
    "import glob\n",
    "fname = 'p1'\n",
    "def create_sentiment_document(name, text, index):\n",
    "    _, split, sentiment_str, _ = name.split('/')\n",
    "    sentiment = {'POS': 1.0, 'NEG': 0.0}[sentiment_str]\n",
    "    tokens = text.split()\n",
    "    return SentimentDocument(tokens, [index], split, sentiment)\n",
    "\n",
    "def extract_documents():\n",
    "    index = 0\n",
    "    \n",
    "    for files in glob.glob(fname +\"/*/*/*.txt\"):\n",
    "        if re.match(r'p1/test/(POS|NEG)/.*_\\d+.txt$', files):\n",
    "            with open(files, 'r+',encoding='utf8') as f:\n",
    "                temp = f.read().replace(\"\\n\",\"\").replace('<br />', ' ')\n",
    "                member_text= ''.join(temp)  \n",
    "#                 print(member_text)\n",
    "                assert member_text.count('\\n') == 0\n",
    "                yield create_sentiment_document(files, member_text, index)\n",
    "                index += 1\n",
    "\n",
    "p1docs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1docs[99].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a single document looks like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentDocument(words=['I', 'love', 'sci-fi', 'and', 'am', 'willing', 'to', 'put', 'up', 'with', 'a', 'lot.', 'Sci-fi', 'movies/TV', 'are', 'usually', 'underfunded,', 'under-appreciated', 'and', 'misunderstood.', 'I', 'tried', 'to', 'like', 'this,', 'I', 'really', 'did,', 'but', 'it', 'is', 'to', 'good', 'TV', 'sci-fi', 'as', 'Babylon', '5', 'is', 'to', 'Star', 'Trek', '(the', 'original).', 'Silly', 'prosthetics,', 'cheap', 'cardboard', 'sets,', 'stilted', 'dialogues,', 'CG', 'that', \"doesn't\", 'match', 'the', 'background,', 'and', 'painfully', 'one-dimensional', 'characters', 'cannot', 'be', 'overcome', 'with', 'a', \"'sci-fi'\", 'setting.', \"(I'm\", 'sure', 'there', 'are', 'those', 'of', 'you', 'out', 'there', 'who', 'think', 'Babylon', '5', 'is', 'good', 'sci-fi', 'TV.', \"It's\", 'not.', \"It's\", 'clich√©d', 'and', 'uninspiring.)', 'While', 'US', 'viewers', 'might', 'like', 'emotion', 'and', 'character', 'development,', 'sci-fi', 'is', 'a', 'genre', 'that', 'does', 'not', 'take', 'itself', 'seriously', '(cf.', 'Star', 'Trek).', 'It', 'may', 'treat', 'important', 'issues,', 'yet', 'not', 'as', 'a', 'serious', 'philosophy.', \"It's\", 'really', 'difficult', 'to', 'care', 'about', 'the', 'characters', 'here', 'as', 'they', 'are', 'not', 'simply', 'foolish,', 'just', 'missing', 'a', 'spark', 'of', 'life.', 'Their', 'actions', 'and', 'reactions', 'are', 'wooden', 'and', 'predictable,', 'often', 'painful', 'to', 'watch.', 'The', 'makers', 'of', 'Earth', 'KNOW', \"it's\", 'rubbish', 'as', 'they', 'have', 'to', 'always', 'say', '\"Gene', \"Roddenberry's\", 'Earth...\"', 'otherwise', 'people', 'would', 'not', 'continue', 'watching.', \"Roddenberry's\", 'ashes', 'must', 'be', 'turning', 'in', 'their', 'orbit', 'as', 'this', 'dull,', 'cheap,', 'poorly', 'edited', '(watching', 'it', 'without', 'advert', 'breaks', 'really', 'brings', 'this', 'home)', 'trudging', 'Trabant', 'of', 'a', 'show', 'lumbers', 'into', 'space.', 'Spoiler.', 'So,', 'kill', 'off', 'a', 'main', 'character.', 'And', 'then', 'bring', 'him', 'back', 'as', 'another', 'actor.', 'Jeeez!', 'Dallas', 'all', 'over', 'again.'], tags=[0], split='test', sentiment=0.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print(np.shape(alldocs))\n",
    "print(alldocs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract our documents and split into training/test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "#the original training and testing dataset\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(alldocs), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the tags can be used to do the round-robin splitting. Note:tags are \"tag=\\[n\\]\" shown in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_splits(target,splits=10):\n",
    "    length = len(target)\n",
    "    #if flatten\n",
    "    temp = np.reshape(target,(splits,length//splits,4),order= \"F\").reshape((length,4))\n",
    "    for item in temp:\n",
    "        yield SentimentDocument._make(item)\n",
    "\n",
    "#     return np.reshape(target,(splits,length//splits,4),order= \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Note that the value of tags for train_docs starts from 25000;\n",
    "Training on both train and test dataset for a blind test set: 50,000reviews\n",
    "The blind test set uses p1's 10% dataset after cv(that is the first fold)\n",
    "'''\n",
    "\n",
    "'''\n",
    "Only train on the assumed training dataset\n",
    "'''\n",
    "#process the training dataset\n",
    "train_docs_p2 = test_docs+train_docs\n",
    "cv_train_docs = list(cv_splits(train_docs_p2))\n",
    "\n",
    "#process the testing dataset\n",
    "_test_docs = list(cv_splits(p1docs))\n",
    "cv_test_docs = _test_docs[:200]\n",
    "# del cv_test_docs[200:] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_train_docs[37699].split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up Doc2Vec Training & Evaluation Models\n",
    "-------------------------------------------\n",
    "We approximate the experiment of Le & Mikolov `\"Distributed Representations\n",
    "of Sentences and Documents\"\n",
    "<http://cs.stanford.edu/~quocle/paragraph_vector.pdf>`_ with guidance from\n",
    "Mikolov's `example go.sh\n",
    "<https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ>`_::\n",
    "\n",
    "    ./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1\n",
    "\n",
    "We vary the following parameter choices:\n",
    "\n",
    "* 100-dimensional vectors, as the 400-d vectors of the paper take a lot of\n",
    "  memory and, in our tests of this task, don't seem to offer much benefit\n",
    "* Similarly, frequent word subsampling seems to decrease sentiment-prediction\n",
    "  accuracy, so it's left out\n",
    "* ``cbow=0`` means skip-gram which is equivalent to the paper's 'PV-DBOW'\n",
    "  mode, matched in gensim with ``dm=0``\n",
    "* Added to that DBOW model are two DM models, one which averages context\n",
    "  vectors (\\ ``dm_mean``\\ ) and one which concatenates them (\\ ``dm_concat``\\ ,\n",
    "  resulting in a much larger, slower, more data-hungry model)\n",
    "* A ``min_count=2`` saves quite a bit of model memory, discarding only words\n",
    "  that appear in a single doc (and are thus no more expressive than the\n",
    "  unique-to-each doc vectors themselves)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:06:53,365 : INFO : using concatenative 1100-dimensional layer1\n",
      "2019-12-29 16:06:53,367 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:06:53,367 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-12-29 16:06:53,737 : INFO : PROGRESS: at example #10000, processed 2292381 words (6206375/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:06:54,122 : INFO : PROGRESS: at example #20000, processed 4573645 words (5938740/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:06:54,529 : INFO : PROGRESS: at example #30000, processed 6865575 words (5639240/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:06:54,946 : INFO : PROGRESS: at example #40000, processed 9190019 words (5596134/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:06:55,349 : INFO : PROGRESS: at example #50000, processed 11557847 words (5877182/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:06:55,741 : INFO : PROGRESS: at example #60000, processed 13899883 words (5988758/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:06:56,143 : INFO : PROGRESS: at example #70000, processed 16270094 words (5897148/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:06:56,541 : INFO : PROGRESS: at example #80000, processed 18598876 words (5862299/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:06:56,938 : INFO : PROGRESS: at example #90000, processed 20916044 words (5854189/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:06:57,345 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:06:57,346 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:06:58,774 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:06:58,775 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:06:59,330 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:06:59,344 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:06:59,344 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:07:00,119 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 16:07:00,120 : INFO : resetting layer weights\n",
      "2019-12-29 16:07:53,430 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:07:53,431 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:07:53,778 : INFO : PROGRESS: at example #10000, processed 2292381 words (6611301/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:07:54,160 : INFO : PROGRESS: at example #20000, processed 4573645 words (5987644/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:07:54,534 : INFO : PROGRESS: at example #30000, processed 6865575 words (6140708/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:07:54,922 : INFO : PROGRESS: at example #40000, processed 9190019 words (6001396/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:07:55,303 : INFO : PROGRESS: at example #50000, processed 11557847 words (6218490/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:07:55,688 : INFO : PROGRESS: at example #60000, processed 13899883 words (6099242/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:07:56,083 : INFO : PROGRESS: at example #70000, processed 16270094 words (6002780/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:07:56,470 : INFO : PROGRESS: at example #80000, processed 18598876 words (6035444/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:07:56,852 : INFO : PROGRESS: at example #90000, processed 20916044 words (6075503/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:07:57,244 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:07:57,244 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:07:58,660 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:07:58,660 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:07:59,215 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:07:59,229 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:07:59,230 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:08:00,002 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 16:08:00,002 : INFO : resetting layer weights\n",
      "2019-12-29 16:08:54,570 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:08:54,571 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:08:54,919 : INFO : PROGRESS: at example #10000, processed 2292381 words (6584333/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:08:55,300 : INFO : PROGRESS: at example #20000, processed 4573645 words (5998692/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:08:55,714 : INFO : PROGRESS: at example #30000, processed 6865575 words (5547343/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:08:56,144 : INFO : PROGRESS: at example #40000, processed 9190019 words (5407887/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:08:56,682 : INFO : PROGRESS: at example #50000, processed 11557847 words (4409087/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:08:57,125 : INFO : PROGRESS: at example #60000, processed 13899883 words (5295670/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:08:57,525 : INFO : PROGRESS: at example #70000, processed 16270094 words (5940754/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:08:57,907 : INFO : PROGRESS: at example #80000, processed 18598876 words (6093663/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:08:58,297 : INFO : PROGRESS: at example #90000, processed 20916044 words (5951675/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:08:58,699 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:08:58,700 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:08:59,755 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:08:59,755 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:09:00,324 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:09:00,338 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:09:00,339 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:09:01,133 : INFO : estimated required memory for 265408 words and 100 dimensions: 1446662400 bytes\n",
      "2019-12-29 16:09:01,133 : INFO : resetting layer weights\n",
      "2019-12-29 16:09:54,066 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:09:54,066 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:09:54,751 : INFO : PROGRESS: at example #10000, processed 2292381 words (3351045/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:09:55,127 : INFO : PROGRESS: at example #20000, processed 4573645 words (6080310/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:09:55,510 : INFO : PROGRESS: at example #30000, processed 6865575 words (6003234/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:09:56,040 : INFO : PROGRESS: at example #40000, processed 9190019 words (4390499/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:09:56,446 : INFO : PROGRESS: at example #50000, processed 11557847 words (5848753/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:09:56,843 : INFO : PROGRESS: at example #60000, processed 13899883 words (5905066/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:09:57,248 : INFO : PROGRESS: at example #70000, processed 16270094 words (5853833/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:09:57,635 : INFO : PROGRESS: at example #80000, processed 18598876 words (6041086/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:09:58,020 : INFO : PROGRESS: at example #90000, processed 20916044 words (6019276/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:09:58,417 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:09:58,418 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:09:59,439 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:09:59,440 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:09:59,998 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:10:00,012 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:10:00,013 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:10:00,789 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 16:10:00,789 : INFO : resetting layer weights\n",
      "2019-12-29 16:10:51,586 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:10:51,586 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w2,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:10:51,923 : INFO : PROGRESS: at example #10000, processed 2292381 words (6825395/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:10:52,279 : INFO : PROGRESS: at example #20000, processed 4573645 words (6416892/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:10:52,646 : INFO : PROGRESS: at example #30000, processed 6865575 words (6255750/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:10:53,033 : INFO : PROGRESS: at example #40000, processed 9190019 words (6016329/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:10:53,420 : INFO : PROGRESS: at example #50000, processed 11557847 words (6129708/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:10:53,802 : INFO : PROGRESS: at example #60000, processed 13899883 words (6145852/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:10:54,193 : INFO : PROGRESS: at example #70000, processed 16270094 words (6066147/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:10:54,593 : INFO : PROGRESS: at example #80000, processed 18598876 words (5827198/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:10:54,978 : INFO : PROGRESS: at example #90000, processed 20916044 words (6042234/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:10:55,376 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:10:55,377 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:10:55,892 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:10:55,893 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:10:56,463 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:10:56,476 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:10:56,477 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:10:57,251 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 16:10:57,251 : INFO : resetting layer weights\n",
      "2019-12-29 16:11:48,473 : INFO : collecting all words and their counts\n",
      "2019-12-29 16:11:48,473 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"alpha=0.025\",dm/m,d100,n5,w10,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 16:11:48,815 : INFO : PROGRESS: at example #10000, processed 2292381 words (6716571/s), 150816 word types, 10000 tags\n",
      "2019-12-29 16:11:49,166 : INFO : PROGRESS: at example #20000, processed 4573645 words (6513553/s), 238497 word types, 20000 tags\n",
      "2019-12-29 16:11:49,532 : INFO : PROGRESS: at example #30000, processed 6865575 words (6270864/s), 312348 word types, 30000 tags\n",
      "2019-12-29 16:11:49,921 : INFO : PROGRESS: at example #40000, processed 9190019 words (5985161/s), 377231 word types, 40000 tags\n",
      "2019-12-29 16:11:50,312 : INFO : PROGRESS: at example #50000, processed 11557847 words (6065485/s), 438729 word types, 50000 tags\n",
      "2019-12-29 16:11:50,694 : INFO : PROGRESS: at example #60000, processed 13899883 words (6140063/s), 493913 word types, 60000 tags\n",
      "2019-12-29 16:11:51,093 : INFO : PROGRESS: at example #70000, processed 16270094 words (5951262/s), 548474 word types, 70000 tags\n",
      "2019-12-29 16:11:51,478 : INFO : PROGRESS: at example #80000, processed 18598876 words (6056160/s), 598272 word types, 80000 tags\n",
      "2019-12-29 16:11:51,872 : INFO : PROGRESS: at example #90000, processed 20916044 words (5882007/s), 646082 word types, 90000 tags\n",
      "2019-12-29 16:11:52,269 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 16:11:52,270 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 16:11:53,336 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 16:11:53,336 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 16:11:53,909 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 16:11:53,922 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 16:11:53,923 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 16:11:54,196 : INFO : constructing a huffman tree from 265408 words\n",
      "2019-12-29 16:17:05,149 : INFO : built huffman tree with maximum node depth 24\n",
      "2019-12-29 16:17:05,657 : INFO : estimated required memory for 265408 words and 100 dimensions: 544275200 bytes\n",
      "2019-12-29 16:17:05,658 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"hs=0\",dm/m,d100,n5,hs,w5,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "#the first recording\n",
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "common_kwargs = dict(\n",
    "    vector_size=100, epochs=20, min_alpha = 1e-3, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n",
    ")\n",
    "common_kwargs_hs1 = dict(\n",
    "    vector_size=100, epochs=20, min_alpha = 1e-3, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=1,\n",
    ")\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, **common_kwargs),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, window=10, alpha=0.05, comment='alpha=0.05', **common_kwargs),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, window=5, **common_kwargs),\n",
    "    # new added\n",
    "    Doc2Vec(dm=1, window=2, alpha=0.05, comment='alpha=0.05', **common_kwargs),\n",
    "    Doc2Vec(dm=1, window=10, alpha=0.025, comment='alpha=0.025', **common_kwargs),\n",
    "    Doc2Vec(dm=1, window=5, comment='hs=0', **common_kwargs_hs1),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "#     path = str(model)+\".model\"\n",
    "    model.build_vocab(alldocs)\n",
    "#     model.save(path)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 21:22:31,081 : INFO : collecting all words and their counts\n",
      "2019-12-29 21:22:31,082 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-12-29 21:22:31,469 : INFO : PROGRESS: at example #10000, processed 2292381 words (5955446/s), 150816 word types, 10000 tags\n",
      "2019-12-29 21:22:31,925 : INFO : PROGRESS: at example #20000, processed 4573645 words (5009225/s), 238497 word types, 20000 tags\n",
      "2019-12-29 21:22:32,431 : INFO : PROGRESS: at example #30000, processed 6865575 words (4536743/s), 312348 word types, 30000 tags\n",
      "2019-12-29 21:22:32,970 : INFO : PROGRESS: at example #40000, processed 9190019 words (4321001/s), 377231 word types, 40000 tags\n",
      "2019-12-29 21:22:33,531 : INFO : PROGRESS: at example #50000, processed 11557847 words (4217995/s), 438729 word types, 50000 tags\n",
      "2019-12-29 21:22:34,123 : INFO : PROGRESS: at example #60000, processed 13899883 words (3965459/s), 493913 word types, 60000 tags\n",
      "2019-12-29 21:22:34,721 : INFO : PROGRESS: at example #70000, processed 16270094 words (3968326/s), 548474 word types, 70000 tags\n",
      "2019-12-29 21:22:35,200 : INFO : PROGRESS: at example #80000, processed 18598876 words (4864102/s), 598272 word types, 80000 tags\n",
      "2019-12-29 21:22:35,601 : INFO : PROGRESS: at example #90000, processed 20916044 words (5781924/s), 646082 word types, 90000 tags\n",
      "2019-12-29 21:22:36,008 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 21:22:36,009 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 21:22:36,526 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 21:22:36,526 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 21:22:37,086 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 21:22:37,099 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 21:22:37,099 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 21:22:37,749 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 21:22:37,750 : INFO : resetting layer weights\n",
      "2019-12-29 21:23:31,056 : INFO : collecting all words and their counts\n",
      "2019-12-29 21:23:31,057 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 21:23:31,409 : INFO : PROGRESS: at example #10000, processed 2292381 words (6529284/s), 150816 word types, 10000 tags\n",
      "2019-12-29 21:23:31,762 : INFO : PROGRESS: at example #20000, processed 4573645 words (6473825/s), 238497 word types, 20000 tags\n",
      "2019-12-29 21:23:32,120 : INFO : PROGRESS: at example #30000, processed 6865575 words (6419631/s), 312348 word types, 30000 tags\n",
      "2019-12-29 21:23:32,511 : INFO : PROGRESS: at example #40000, processed 9190019 words (5955064/s), 377231 word types, 40000 tags\n",
      "2019-12-29 21:23:32,897 : INFO : PROGRESS: at example #50000, processed 11557847 words (6136023/s), 438729 word types, 50000 tags\n",
      "2019-12-29 21:23:33,281 : INFO : PROGRESS: at example #60000, processed 13899883 words (6113918/s), 493913 word types, 60000 tags\n",
      "2019-12-29 21:23:33,677 : INFO : PROGRESS: at example #70000, processed 16270094 words (5997696/s), 548474 word types, 70000 tags\n",
      "2019-12-29 21:23:34,058 : INFO : PROGRESS: at example #80000, processed 18598876 words (6115735/s), 598272 word types, 80000 tags\n",
      "2019-12-29 21:23:34,440 : INFO : PROGRESS: at example #90000, processed 20916044 words (6083182/s), 646082 word types, 90000 tags\n",
      "2019-12-29 21:23:34,839 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 21:23:34,839 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 21:23:35,383 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 21:23:35,383 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 21:23:35,930 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 21:23:35,943 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 21:23:35,943 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 21:23:36,683 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 21:23:36,684 : INFO : resetting layer weights\n",
      "2019-12-29 21:24:29,841 : INFO : collecting all words and their counts\n",
      "2019-12-29 21:24:29,841 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"w2\",dm/m,d100,n5,w2,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 21:24:30,194 : INFO : PROGRESS: at example #10000, processed 2292381 words (6514034/s), 150816 word types, 10000 tags\n",
      "2019-12-29 21:24:30,550 : INFO : PROGRESS: at example #20000, processed 4573645 words (6419475/s), 238497 word types, 20000 tags\n",
      "2019-12-29 21:24:30,911 : INFO : PROGRESS: at example #30000, processed 6865575 words (6357057/s), 312348 word types, 30000 tags\n",
      "2019-12-29 21:24:31,294 : INFO : PROGRESS: at example #40000, processed 9190019 words (6080518/s), 377231 word types, 40000 tags\n",
      "2019-12-29 21:24:31,681 : INFO : PROGRESS: at example #50000, processed 11557847 words (6120498/s), 438729 word types, 50000 tags\n",
      "2019-12-29 21:24:32,071 : INFO : PROGRESS: at example #60000, processed 13899883 words (6026253/s), 493913 word types, 60000 tags\n",
      "2019-12-29 21:24:32,467 : INFO : PROGRESS: at example #70000, processed 16270094 words (5998100/s), 548474 word types, 70000 tags\n",
      "2019-12-29 21:24:32,858 : INFO : PROGRESS: at example #80000, processed 18598876 words (5956205/s), 598272 word types, 80000 tags\n",
      "2019-12-29 21:24:33,250 : INFO : PROGRESS: at example #90000, processed 20916044 words (5930227/s), 646082 word types, 90000 tags\n",
      "2019-12-29 21:24:33,644 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 21:24:33,645 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 21:24:33,983 : INFO : effective_min_count=5 retains 120726 unique words (17% of original 693922, drops 573196)\n",
      "2019-12-29 21:24:33,983 : INFO : effective_min_count=5 leaves 22478286 word corpus (96% of original 23279529, drops 801243)\n",
      "2019-12-29 21:24:34,230 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 21:24:34,242 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 21:24:34,243 : INFO : downsampling leaves estimated 22478286 word corpus (100.0% of prior 22478286)\n",
      "2019-12-29 21:24:34,601 : INFO : estimated required memory for 120726 words and 100 dimensions: 196943800 bytes\n",
      "2019-12-29 21:24:34,602 : INFO : resetting layer weights\n",
      "2019-12-29 21:25:06,309 : INFO : collecting all words and their counts\n",
      "2019-12-29 21:25:06,311 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"mc5w5\",dm/m,d100,n5,w5,mc5,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 21:25:06,655 : INFO : PROGRESS: at example #10000, processed 2292381 words (6695475/s), 150816 word types, 10000 tags\n",
      "2019-12-29 21:25:07,007 : INFO : PROGRESS: at example #20000, processed 4573645 words (6484377/s), 238497 word types, 20000 tags\n",
      "2019-12-29 21:25:07,371 : INFO : PROGRESS: at example #30000, processed 6865575 words (6307714/s), 312348 word types, 30000 tags\n",
      "2019-12-29 21:25:07,756 : INFO : PROGRESS: at example #40000, processed 9190019 words (6049073/s), 377231 word types, 40000 tags\n",
      "2019-12-29 21:25:08,138 : INFO : PROGRESS: at example #50000, processed 11557847 words (6215443/s), 438729 word types, 50000 tags\n",
      "2019-12-29 21:25:08,517 : INFO : PROGRESS: at example #60000, processed 13899883 words (6182495/s), 493913 word types, 60000 tags\n",
      "2019-12-29 21:25:08,907 : INFO : PROGRESS: at example #70000, processed 16270094 words (6092665/s), 548474 word types, 70000 tags\n",
      "2019-12-29 21:25:09,295 : INFO : PROGRESS: at example #80000, processed 18598876 words (6007425/s), 598272 word types, 80000 tags\n",
      "2019-12-29 21:25:09,683 : INFO : PROGRESS: at example #90000, processed 20916044 words (5980581/s), 646082 word types, 90000 tags\n",
      "2019-12-29 21:25:10,075 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2019-12-29 21:25:10,076 : INFO : Loading a fresh vocabulary\n",
      "2019-12-29 21:25:11,700 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2019-12-29 21:25:11,701 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2019-12-29 21:25:12,254 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2019-12-29 21:25:12,267 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-12-29 21:25:12,268 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2019-12-29 21:25:13,024 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2019-12-29 21:25:13,025 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"mc5w2\",dm/m,d100,n5,w2,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "#the second recording\n",
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "common_kwargs = dict(\n",
    "    vector_size=100, epochs=10, min_alpha = 1e-3, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n",
    ")\n",
    "common_kwargs_mc5 = dict(\n",
    "    vector_size=100, epochs=10, min_alpha = 1e-3, min_count=5,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n",
    ")\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, **common_kwargs),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, window=2, alpha=0.05, comment='w2', **common_kwargs),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "#     Doc2Vec(dm=1, dm_concat=1, window=5, **common_kwargs),\n",
    "    # new added\n",
    "    Doc2Vec(dm=1, window=5, alpha=0.05, comment='mc5w5', **common_kwargs_mc5),\n",
    "    Doc2Vec(dm=1, window=2, alpha=0.05, comment='mc5w2', **common_kwargs),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "#     path = str(model)+\".model\"\n",
    "    model.build_vocab(alldocs)\n",
    "#     model.save(path)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:05:12,671 : INFO : collecting all words and their counts\n",
      "2020-01-08 21:05:12,672 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-01-08 21:05:13,030 : INFO : PROGRESS: at example #10000, processed 2292381 words (6412931/s), 150816 word types, 10000 tags\n",
      "2020-01-08 21:05:13,428 : INFO : PROGRESS: at example #20000, processed 4573645 words (5749204/s), 238497 word types, 20000 tags\n",
      "2020-01-08 21:05:13,824 : INFO : PROGRESS: at example #30000, processed 6865575 words (5797971/s), 312348 word types, 30000 tags\n",
      "2020-01-08 21:05:14,245 : INFO : PROGRESS: at example #40000, processed 9190019 words (5526029/s), 377231 word types, 40000 tags\n",
      "2020-01-08 21:05:14,656 : INFO : PROGRESS: at example #50000, processed 11557847 words (5764988/s), 438729 word types, 50000 tags\n",
      "2020-01-08 21:05:15,063 : INFO : PROGRESS: at example #60000, processed 13899883 words (5766633/s), 493913 word types, 60000 tags\n",
      "2020-01-08 21:05:15,468 : INFO : PROGRESS: at example #70000, processed 16270094 words (5856221/s), 548474 word types, 70000 tags\n",
      "2020-01-08 21:05:15,864 : INFO : PROGRESS: at example #80000, processed 18598876 words (5897566/s), 598272 word types, 80000 tags\n",
      "2020-01-08 21:05:16,276 : INFO : PROGRESS: at example #90000, processed 20916044 words (5630923/s), 646082 word types, 90000 tags\n",
      "2020-01-08 21:05:16,712 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2020-01-08 21:05:16,713 : INFO : Loading a fresh vocabulary\n",
      "2020-01-08 21:05:18,003 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2020-01-08 21:05:18,004 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2020-01-08 21:05:18,590 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2020-01-08 21:05:18,609 : INFO : sample=0 downsamples 0 most-common words\n",
      "2020-01-08 21:05:18,609 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2020-01-08 21:05:19,340 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2020-01-08 21:05:19,341 : INFO : resetting layer weights\n",
      "2020-01-08 21:06:14,930 : INFO : collecting all words and their counts\n",
      "2020-01-08 21:06:14,931 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:06:15,248 : INFO : PROGRESS: at example #10000, processed 2292381 words (7231367/s), 150816 word types, 10000 tags\n",
      "2020-01-08 21:06:15,572 : INFO : PROGRESS: at example #20000, processed 4573645 words (7056478/s), 238497 word types, 20000 tags\n",
      "2020-01-08 21:06:15,933 : INFO : PROGRESS: at example #30000, processed 6865575 words (6366644/s), 312348 word types, 30000 tags\n",
      "2020-01-08 21:06:16,323 : INFO : PROGRESS: at example #40000, processed 9190019 words (5967488/s), 377231 word types, 40000 tags\n",
      "2020-01-08 21:06:16,719 : INFO : PROGRESS: at example #50000, processed 11557847 words (5986612/s), 438729 word types, 50000 tags\n",
      "2020-01-08 21:06:17,107 : INFO : PROGRESS: at example #60000, processed 13899883 words (6047371/s), 493913 word types, 60000 tags\n",
      "2020-01-08 21:06:17,497 : INFO : PROGRESS: at example #70000, processed 16270094 words (6078932/s), 548474 word types, 70000 tags\n",
      "2020-01-08 21:06:17,868 : INFO : PROGRESS: at example #80000, processed 18598876 words (6290778/s), 598272 word types, 80000 tags\n",
      "2020-01-08 21:06:18,258 : INFO : PROGRESS: at example #90000, processed 20916044 words (5948695/s), 646082 word types, 90000 tags\n",
      "2020-01-08 21:06:18,664 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2020-01-08 21:06:18,664 : INFO : Loading a fresh vocabulary\n",
      "2020-01-08 21:06:19,629 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2020-01-08 21:06:19,630 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2020-01-08 21:06:20,210 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2020-01-08 21:06:20,222 : INFO : sample=0 downsamples 0 most-common words\n",
      "2020-01-08 21:06:20,223 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2020-01-08 21:06:20,953 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2020-01-08 21:06:20,954 : INFO : resetting layer weights\n",
      "2020-01-08 21:07:14,987 : INFO : collecting all words and their counts\n",
      "2020-01-08 21:07:14,988 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:07:15,317 : INFO : PROGRESS: at example #10000, processed 2292381 words (6969724/s), 150816 word types, 10000 tags\n",
      "2020-01-08 21:07:15,653 : INFO : PROGRESS: at example #20000, processed 4573645 words (6805052/s), 238497 word types, 20000 tags\n",
      "2020-01-08 21:07:16,012 : INFO : PROGRESS: at example #30000, processed 6865575 words (6391741/s), 312348 word types, 30000 tags\n",
      "2020-01-08 21:07:16,386 : INFO : PROGRESS: at example #40000, processed 9190019 words (6231791/s), 377231 word types, 40000 tags\n",
      "2020-01-08 21:07:16,763 : INFO : PROGRESS: at example #50000, processed 11557847 words (6283542/s), 438729 word types, 50000 tags\n",
      "2020-01-08 21:07:17,135 : INFO : PROGRESS: at example #60000, processed 13899883 words (6309707/s), 493913 word types, 60000 tags\n",
      "2020-01-08 21:07:17,505 : INFO : PROGRESS: at example #70000, processed 16270094 words (6418973/s), 548474 word types, 70000 tags\n",
      "2020-01-08 21:07:17,870 : INFO : PROGRESS: at example #80000, processed 18598876 words (6397570/s), 598272 word types, 80000 tags\n",
      "2020-01-08 21:07:18,237 : INFO : PROGRESS: at example #90000, processed 20916044 words (6323924/s), 646082 word types, 90000 tags\n",
      "2020-01-08 21:07:18,610 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2020-01-08 21:07:18,611 : INFO : Loading a fresh vocabulary\n",
      "2020-01-08 21:07:20,042 : INFO : effective_min_count=2 retains 265408 unique words (38% of original 693922, drops 428514)\n",
      "2020-01-08 21:07:20,042 : INFO : effective_min_count=2 leaves 22851015 word corpus (98% of original 23279529, drops 428514)\n",
      "2020-01-08 21:07:20,617 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2020-01-08 21:07:20,630 : INFO : sample=0 downsamples 0 most-common words\n",
      "2020-01-08 21:07:20,631 : INFO : downsampling leaves estimated 22851015 word corpus (100.0% of prior 22851015)\n",
      "2020-01-08 21:07:21,352 : INFO : estimated required memory for 265408 words and 100 dimensions: 385030400 bytes\n",
      "2020-01-08 21:07:21,353 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "#the third round:optimisation round\n",
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "common_kwargs = dict(\n",
    "    vector_size=100, epochs=20, min_alpha = 1e-3, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n",
    ")\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, **common_kwargs),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, dm_mean=1, window=2, alpha=0.05, comment='mean', **common_kwargs),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_mean=0, window=2, alpha=0.05, comment='sum', **common_kwargs),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "#     path = str(model)+\".model\"\n",
    "    model.build_vocab(alldocs)\n",
    "#     model.save(path)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le and Mikolov note that combining a paragraph vector from Distributed Bag of\n",
    "Words (DBOW) and Distributed Memory (DM) improves performance. We will\n",
    "follow, pairing the models together for evaluation. Here, we concatenate the\n",
    "paragraph vectors obtained from each model with the help of a thin wrapper\n",
    "class included in a gensim test module. (Note that this a separate, later\n",
    "concatenation of output-vectors than the kind of input-window-concatenation\n",
    "enabled by the ``dm_concat=1`` mode above.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:08:17,412 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-01-08 21:08:17,413 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gensim.models.doc2vec.Doc2Vec at 0x1a8e7528d0>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x1a8e752950>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x1a8e752b10>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x1a1aceda90>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x1a1aceded0>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x1a8e752c50>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Evaluation Methods\n",
    "-----------------------------\n",
    "\n",
    "Given a document, our ``Doc2Vec`` models output a vector representation of the document.\n",
    "How useful is a particular model?\n",
    "In case of sentiment analysis, we want the ouput vector to reflect the sentiment in the input document.\n",
    "So, in vector space, positive documents should be distant from negative documents.\n",
    "\n",
    "We train a logistic regression from the training set:\n",
    "\n",
    "  - regressors (inputs): document vectors from the Doc2Vec model\n",
    "  - target (outpus): sentiment labels\n",
    "\n",
    "So, this logistic regression will be able to predict sentiment given a document vector.\n",
    "\n",
    "Next, we test our logistic regression on the test set, and measure the rate of errors (incorrect predictions).\n",
    "If the document vectors from the Doc2Vec model reflect the actual sentiment well, the error rate will be low.\n",
    "\n",
    "Therefore, the error rate of the logistic regression is indication of *how well* the given Doc2Vec model represents documents as vectors.\n",
    "We can then compare different ``Doc2Vec`` models by looking at their error rates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "#     \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
    "#     logit = sm.Logit(train_targets, train_regressors)\n",
    "#     predictor = logit.fit(disp=0)\n",
    "#     # print(predictor.summary())\n",
    "#     return predictor\n",
    "\n",
    "# def SVM_pred_from_data(train_targets, train_features):\n",
    "#     svm_clf = SGDClassifier(alpha=1e-3,warm_start=True)\n",
    "#     predictor = svm_clf.fit(train_features,train_targets)\n",
    "#     return predictor\n",
    "\n",
    "def SVM_pred_from_data_cv(train_targets, train_features):\n",
    "#     svm_clf = SGDClassifier(alpha=1e-3,warm_start=True,early_stopping=True,validation_fraction=0.1)\n",
    "    svm_clf = SGDClassifier(alpha=1e-3)\n",
    "#     svm_clf = svm.SVC(kernel='linear')\n",
    "#     svm_clf = svm.SVC(kernel='poly')\n",
    "#     svm_clf = svm.SVC(kernel='rbf')\n",
    "#     svm_clf = svm.SVC(kernel='sigmoid')\n",
    "    predictor = svm_clf.fit(train_features,train_targets)\n",
    "        \n",
    "    return predictor\n",
    "\n",
    "\n",
    "def result_rates_for_model(test_model, train_set, test_docvecs, test_targets):\n",
    "    \"\"\"Report error rate and correct rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_features = [test_model.docvecs[doc.tags[0]] for doc in train_set]\n",
    "#     this is not lofic regression so don't need to add \"b\"(in y=ax+b)\n",
    "#     train_regressors = sm.add_constant(train_regressors) \n",
    "#     predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "#     predictor = SVM_pred_from_data(train_targets,train_features)\n",
    "    predictor = SVM_pred_from_data_cv(train_targets,train_features)\n",
    "\n",
    "    '''Note:change the volume of testdata and the name'''\n",
    "\n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_docvecs)\n",
    "    num_test = len(test_predictions)\n",
    "    corrects = sum(np.rint(test_predictions) == test_targets)\n",
    "    errors =  num_test - corrects\n",
    "    error_rate = float(errors) / num_test\n",
    "    correct_rate = float(corrects) / num_test\n",
    "    return (error_rate, errors, correct_rate, corrects, num_test, predictor, test_predictions, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk Training & Per-Model Evaluation\n",
    "------------------------------------\n",
    "\n",
    "Note that doc-vector training is occurring on *all* documents of the dataset,\n",
    "which includes all TRAIN/TEST/DEV docs.  Because the native document-order\n",
    "has similar-sentiment documents in large clumps ‚Äì which is suboptimal for\n",
    "training ‚Äì we work with once-shuffled copy of the training set.\n",
    "\n",
    "We evaluate each model's sentiment predictive power based on error rate, and\n",
    "the evaluation is done for each model.\n",
    "\n",
    "(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3\n",
    "main models takes about an hour.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "error_rates = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training doc2vec model on 10,000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:08:18,900 : INFO : training model with 8 workers on 265408 vocabulary and 100 features, using sg=1 hs=0 sample=0 negative=5 window=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d100,n5,mc2,t8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:08:19,929 : INFO : EPOCH 1 - PROGRESS: at 5.99% examples, 1339433 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:20,933 : INFO : EPOCH 1 - PROGRESS: at 12.82% examples, 1449859 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:21,936 : INFO : EPOCH 1 - PROGRESS: at 19.31% examples, 1458794 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:08:22,950 : INFO : EPOCH 1 - PROGRESS: at 25.84% examples, 1466238 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:23,954 : INFO : EPOCH 1 - PROGRESS: at 32.32% examples, 1462787 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:24,954 : INFO : EPOCH 1 - PROGRESS: at 38.75% examples, 1463026 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:25,961 : INFO : EPOCH 1 - PROGRESS: at 45.33% examples, 1471180 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:08:26,965 : INFO : EPOCH 1 - PROGRESS: at 52.05% examples, 1482183 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:08:27,970 : INFO : EPOCH 1 - PROGRESS: at 58.88% examples, 1494034 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:28,972 : INFO : EPOCH 1 - PROGRESS: at 65.79% examples, 1504212 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:29,974 : INFO : EPOCH 1 - PROGRESS: at 72.69% examples, 1508625 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:30,976 : INFO : EPOCH 1 - PROGRESS: at 79.56% examples, 1512123 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:31,979 : INFO : EPOCH 1 - PROGRESS: at 86.33% examples, 1517300 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:32,991 : INFO : EPOCH 1 - PROGRESS: at 93.31% examples, 1521228 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:33,920 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:08:33,927 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:08:33,937 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:08:33,939 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:08:33,942 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:08:33,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:08:33,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:08:33,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:08:33,952 : INFO : EPOCH - 1 : training on 23279529 raw words (22951015 effective words) took 15.0s, 1525881 effective words/s\n",
      "2020-01-08 21:08:34,963 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 1644293 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:35,971 : INFO : EPOCH 2 - PROGRESS: at 14.74% examples, 1672646 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:08:36,976 : INFO : EPOCH 2 - PROGRESS: at 22.28% examples, 1692046 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:37,977 : INFO : EPOCH 2 - PROGRESS: at 29.78% examples, 1692254 words/s, in_qsize 15, out_qsize 1\n",
      "2020-01-08 21:08:38,984 : INFO : EPOCH 2 - PROGRESS: at 37.25% examples, 1689511 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:39,989 : INFO : EPOCH 2 - PROGRESS: at 44.63% examples, 1691993 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:40,990 : INFO : EPOCH 2 - PROGRESS: at 51.97% examples, 1694363 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:41,996 : INFO : EPOCH 2 - PROGRESS: at 59.17% examples, 1692068 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:42,996 : INFO : EPOCH 2 - PROGRESS: at 66.58% examples, 1694418 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:44,006 : INFO : EPOCH 2 - PROGRESS: at 74.18% examples, 1694613 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:45,010 : INFO : EPOCH 2 - PROGRESS: at 81.70% examples, 1695946 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:46,010 : INFO : EPOCH 2 - PROGRESS: at 89.14% examples, 1697489 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:47,011 : INFO : EPOCH 2 - PROGRESS: at 96.53% examples, 1697107 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:47,440 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:08:47,449 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:08:47,459 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:08:47,461 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:08:47,464 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:08:47,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:08:47,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:08:47,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:08:47,474 : INFO : EPOCH - 2 : training on 23279529 raw words (22951015 effective words) took 13.5s, 1697873 effective words/s\n",
      "2020-01-08 21:08:48,480 : INFO : EPOCH 3 - PROGRESS: at 7.32% examples, 1660656 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:49,489 : INFO : EPOCH 3 - PROGRESS: at 14.74% examples, 1675693 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:50,500 : INFO : EPOCH 3 - PROGRESS: at 22.27% examples, 1690736 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:08:51,504 : INFO : EPOCH 3 - PROGRESS: at 29.74% examples, 1687894 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:52,515 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 1693970 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:53,522 : INFO : EPOCH 3 - PROGRESS: at 45.13% examples, 1708222 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:54,530 : INFO : EPOCH 3 - PROGRESS: at 52.71% examples, 1714854 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:55,530 : INFO : EPOCH 3 - PROGRESS: at 60.39% examples, 1724180 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:56,543 : INFO : EPOCH 3 - PROGRESS: at 67.90% examples, 1722895 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:57,544 : INFO : EPOCH 3 - PROGRESS: at 75.56% examples, 1722865 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:58,548 : INFO : EPOCH 3 - PROGRESS: at 83.10% examples, 1723025 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:08:59,567 : INFO : EPOCH 3 - PROGRESS: at 90.73% examples, 1722869 words/s, in_qsize 15, out_qsize 2\n",
      "2020-01-08 21:09:00,571 : INFO : EPOCH 3 - PROGRESS: at 98.40% examples, 1724736 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:00,740 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:09:00,749 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:09:00,752 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:09:00,755 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:09:00,760 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:09:00,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:09:00,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:09:00,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:09:00,770 : INFO : EPOCH - 3 : training on 23279529 raw words (22951015 effective words) took 13.3s, 1726610 effective words/s\n",
      "2020-01-08 21:09:01,774 : INFO : EPOCH 4 - PROGRESS: at 7.57% examples, 1722971 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:02,788 : INFO : EPOCH 4 - PROGRESS: at 15.29% examples, 1735962 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:03,790 : INFO : EPOCH 4 - PROGRESS: at 22.87% examples, 1739226 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:04,795 : INFO : EPOCH 4 - PROGRESS: at 30.48% examples, 1731304 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:09:05,795 : INFO : EPOCH 4 - PROGRESS: at 38.05% examples, 1726701 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:06,802 : INFO : EPOCH 4 - PROGRESS: at 45.62% examples, 1732276 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:07,804 : INFO : EPOCH 4 - PROGRESS: at 53.20% examples, 1736998 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:08,804 : INFO : EPOCH 4 - PROGRESS: at 60.77% examples, 1740083 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:09,822 : INFO : EPOCH 4 - PROGRESS: at 68.52% examples, 1741371 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:09:10,825 : INFO : EPOCH 4 - PROGRESS: at 76.35% examples, 1743013 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:11,829 : INFO : EPOCH 4 - PROGRESS: at 84.01% examples, 1744632 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:12,848 : INFO : EPOCH 4 - PROGRESS: at 91.66% examples, 1742813 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:13,868 : INFO : EPOCH 4 - PROGRESS: at 99.32% examples, 1741043 words/s, in_qsize 15, out_qsize 1\n",
      "2020-01-08 21:09:13,916 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:09:13,923 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:09:13,925 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:09:13,926 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:09:13,928 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:09:13,932 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:09:13,935 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:09:13,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:09:13,942 : INFO : EPOCH - 4 : training on 23279529 raw words (22951015 effective words) took 13.2s, 1742972 effective words/s\n",
      "2020-01-08 21:09:14,953 : INFO : EPOCH 5 - PROGRESS: at 7.44% examples, 1682946 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:15,964 : INFO : EPOCH 5 - PROGRESS: at 15.19% examples, 1717895 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:16,983 : INFO : EPOCH 5 - PROGRESS: at 22.82% examples, 1724320 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:17,998 : INFO : EPOCH 5 - PROGRESS: at 30.66% examples, 1727446 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:19,000 : INFO : EPOCH 5 - PROGRESS: at 38.29% examples, 1726965 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:20,007 : INFO : EPOCH 5 - PROGRESS: at 45.74% examples, 1727455 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:21,010 : INFO : EPOCH 5 - PROGRESS: at 53.34% examples, 1732560 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:22,014 : INFO : EPOCH 5 - PROGRESS: at 60.93% examples, 1736658 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:23,018 : INFO : EPOCH 5 - PROGRESS: at 68.70% examples, 1740929 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:24,022 : INFO : EPOCH 5 - PROGRESS: at 76.43% examples, 1740493 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:25,025 : INFO : EPOCH 5 - PROGRESS: at 84.10% examples, 1742535 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:26,026 : INFO : EPOCH 5 - PROGRESS: at 91.70% examples, 1742756 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:27,030 : INFO : EPOCH 5 - PROGRESS: at 99.28% examples, 1741597 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:27,090 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:09:27,092 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:09:27,098 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:09:27,101 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:09:27,103 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:09:27,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:09:27,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:09:27,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:09:27,117 : INFO : EPOCH - 5 : training on 23279529 raw words (22951015 effective words) took 13.2s, 1742575 effective words/s\n",
      "2020-01-08 21:09:28,126 : INFO : EPOCH 6 - PROGRESS: at 7.40% examples, 1675562 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:29,126 : INFO : EPOCH 6 - PROGRESS: at 15.14% examples, 1724398 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:30,139 : INFO : EPOCH 6 - PROGRESS: at 22.78% examples, 1731484 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:09:31,145 : INFO : EPOCH 6 - PROGRESS: at 30.48% examples, 1729522 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:32,152 : INFO : EPOCH 6 - PROGRESS: at 38.29% examples, 1734892 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:33,160 : INFO : EPOCH 6 - PROGRESS: at 45.95% examples, 1741387 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:09:34,163 : INFO : EPOCH 6 - PROGRESS: at 53.57% examples, 1746148 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:35,167 : INFO : EPOCH 6 - PROGRESS: at 61.06% examples, 1744837 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:36,168 : INFO : EPOCH 6 - PROGRESS: at 68.57% examples, 1742434 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:37,168 : INFO : EPOCH 6 - PROGRESS: at 76.22% examples, 1740533 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:38,169 : INFO : EPOCH 6 - PROGRESS: at 83.84% examples, 1742165 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:39,171 : INFO : EPOCH 6 - PROGRESS: at 91.54% examples, 1743896 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:40,176 : INFO : EPOCH 6 - PROGRESS: at 99.16% examples, 1743220 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:40,246 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:09:40,249 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:09:40,260 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:09:40,261 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:09:40,264 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:09:40,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:09:40,270 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:09:40,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:09:40,271 : INFO : EPOCH - 6 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1745375 effective words/s\n",
      "2020-01-08 21:09:41,303 : INFO : EPOCH 7 - PROGRESS: at 7.69% examples, 1705913 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:09:42,318 : INFO : EPOCH 7 - PROGRESS: at 15.60% examples, 1745030 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:43,322 : INFO : EPOCH 7 - PROGRESS: at 23.29% examples, 1754105 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:44,325 : INFO : EPOCH 7 - PROGRESS: at 31.01% examples, 1748354 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:45,329 : INFO : EPOCH 7 - PROGRESS: at 38.63% examples, 1744321 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:46,331 : INFO : EPOCH 7 - PROGRESS: at 46.16% examples, 1745082 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:47,338 : INFO : EPOCH 7 - PROGRESS: at 53.77% examples, 1748089 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:48,342 : INFO : EPOCH 7 - PROGRESS: at 61.43% examples, 1751399 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:49,342 : INFO : EPOCH 7 - PROGRESS: at 69.12% examples, 1752812 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:50,351 : INFO : EPOCH 7 - PROGRESS: at 76.92% examples, 1752286 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:51,358 : INFO : EPOCH 7 - PROGRESS: at 84.60% examples, 1753536 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:52,363 : INFO : EPOCH 7 - PROGRESS: at 92.33% examples, 1753740 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:53,330 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:09:53,341 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:09:53,344 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:09:53,348 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:09:53,350 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:09:53,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:09:53,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:09:53,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:09:53,362 : INFO : EPOCH - 7 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1753890 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:09:54,370 : INFO : EPOCH 8 - PROGRESS: at 7.36% examples, 1667977 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:55,376 : INFO : EPOCH 8 - PROGRESS: at 15.14% examples, 1719937 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:56,392 : INFO : EPOCH 8 - PROGRESS: at 22.87% examples, 1733541 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:57,402 : INFO : EPOCH 8 - PROGRESS: at 30.71% examples, 1736534 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:09:58,403 : INFO : EPOCH 8 - PROGRESS: at 38.41% examples, 1738469 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:09:59,406 : INFO : EPOCH 8 - PROGRESS: at 46.08% examples, 1745803 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:00,418 : INFO : EPOCH 8 - PROGRESS: at 53.69% examples, 1747732 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:01,430 : INFO : EPOCH 8 - PROGRESS: at 61.26% examples, 1746907 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:02,436 : INFO : EPOCH 8 - PROGRESS: at 68.90% examples, 1746619 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:03,446 : INFO : EPOCH 8 - PROGRESS: at 76.60% examples, 1743629 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:04,462 : INFO : EPOCH 8 - PROGRESS: at 84.34% examples, 1745104 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:05,469 : INFO : EPOCH 8 - PROGRESS: at 92.06% examples, 1746521 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:06,452 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:10:06,458 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:10:06,463 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:10:06,466 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:10:06,468 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:10:06,471 : INFO : EPOCH 8 - PROGRESS: at 99.92% examples, 1749759 words/s, in_qsize 2, out_qsize 1\n",
      "2020-01-08 21:10:06,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:10:06,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:10:06,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:10:06,479 : INFO : EPOCH - 8 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1750245 effective words/s\n",
      "2020-01-08 21:10:07,484 : INFO : EPOCH 9 - PROGRESS: at 7.61% examples, 1730870 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:08,487 : INFO : EPOCH 9 - PROGRESS: at 15.22% examples, 1734888 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:09,489 : INFO : EPOCH 9 - PROGRESS: at 22.78% examples, 1738490 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:10,498 : INFO : EPOCH 9 - PROGRESS: at 30.39% examples, 1728519 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:10:11,499 : INFO : EPOCH 9 - PROGRESS: at 38.16% examples, 1734217 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:12,502 : INFO : EPOCH 9 - PROGRESS: at 45.79% examples, 1741003 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:13,516 : INFO : EPOCH 9 - PROGRESS: at 53.48% examples, 1745559 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:14,520 : INFO : EPOCH 9 - PROGRESS: at 61.18% examples, 1750405 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:15,522 : INFO : EPOCH 9 - PROGRESS: at 68.86% examples, 1751337 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:16,524 : INFO : EPOCH 9 - PROGRESS: at 76.47% examples, 1747406 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:17,531 : INFO : EPOCH 9 - PROGRESS: at 84.00% examples, 1745710 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:18,539 : INFO : EPOCH 9 - PROGRESS: at 91.70% examples, 1746117 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:19,542 : INFO : EPOCH 9 - PROGRESS: at 99.45% examples, 1747769 words/s, in_qsize 13, out_qsize 0\n",
      "2020-01-08 21:10:19,580 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:10:19,583 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:10:19,588 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:10:19,591 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:10:19,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:10:19,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:10:19,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:10:19,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:10:19,605 : INFO : EPOCH - 9 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1748984 effective words/s\n",
      "2020-01-08 21:10:20,624 : INFO : EPOCH 10 - PROGRESS: at 7.65% examples, 1717353 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:21,629 : INFO : EPOCH 10 - PROGRESS: at 15.38% examples, 1739772 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:22,636 : INFO : EPOCH 10 - PROGRESS: at 23.12% examples, 1752037 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:23,645 : INFO : EPOCH 10 - PROGRESS: at 30.83% examples, 1743920 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:24,648 : INFO : EPOCH 10 - PROGRESS: at 38.45% examples, 1739693 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:25,653 : INFO : EPOCH 10 - PROGRESS: at 45.91% examples, 1738341 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:26,660 : INFO : EPOCH 10 - PROGRESS: at 53.52% examples, 1742371 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:27,661 : INFO : EPOCH 10 - PROGRESS: at 61.09% examples, 1744654 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:28,663 : INFO : EPOCH 10 - PROGRESS: at 68.74% examples, 1745279 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:29,665 : INFO : EPOCH 10 - PROGRESS: at 76.48% examples, 1744846 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:30,666 : INFO : EPOCH 10 - PROGRESS: at 84.20% examples, 1748585 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:31,669 : INFO : EPOCH 10 - PROGRESS: at 91.75% examples, 1746443 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:32,675 : INFO : EPOCH 10 - PROGRESS: at 99.41% examples, 1746139 words/s, in_qsize 14, out_qsize 0\n",
      "2020-01-08 21:10:32,707 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:10:32,717 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:10:32,724 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:10:32,727 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:10:32,728 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:10:32,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:10:32,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:10:32,738 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:10:32,738 : INFO : EPOCH - 10 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1748052 effective words/s\n",
      "2020-01-08 21:10:33,746 : INFO : EPOCH 11 - PROGRESS: at 7.35% examples, 1668896 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:34,747 : INFO : EPOCH 11 - PROGRESS: at 15.14% examples, 1724963 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:35,752 : INFO : EPOCH 11 - PROGRESS: at 22.82% examples, 1739951 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:36,763 : INFO : EPOCH 11 - PROGRESS: at 30.66% examples, 1741176 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:37,764 : INFO : EPOCH 11 - PROGRESS: at 38.45% examples, 1745858 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:38,767 : INFO : EPOCH 11 - PROGRESS: at 45.91% examples, 1744020 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:39,781 : INFO : EPOCH 11 - PROGRESS: at 53.41% examples, 1741598 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:40,784 : INFO : EPOCH 11 - PROGRESS: at 60.95% examples, 1742383 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:41,796 : INFO : EPOCH 11 - PROGRESS: at 68.62% examples, 1742205 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:42,801 : INFO : EPOCH 11 - PROGRESS: at 76.43% examples, 1743419 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:10:43,802 : INFO : EPOCH 11 - PROGRESS: at 84.13% examples, 1746568 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:44,808 : INFO : EPOCH 11 - PROGRESS: at 91.74% examples, 1745636 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:45,811 : INFO : EPOCH 11 - PROGRESS: at 99.52% examples, 1748039 words/s, in_qsize 11, out_qsize 0\n",
      "2020-01-08 21:10:45,829 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:10:45,838 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:10:45,846 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:10:45,849 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:10:45,852 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:10:45,857 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:10:45,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:10:45,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:10:45,860 : INFO : EPOCH - 11 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1749613 effective words/s\n",
      "2020-01-08 21:10:46,867 : INFO : EPOCH 12 - PROGRESS: at 7.61% examples, 1727605 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:47,867 : INFO : EPOCH 12 - PROGRESS: at 15.05% examples, 1716388 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:48,870 : INFO : EPOCH 12 - PROGRESS: at 22.49% examples, 1715929 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:10:49,872 : INFO : EPOCH 12 - PROGRESS: at 30.13% examples, 1717598 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:50,879 : INFO : EPOCH 12 - PROGRESS: at 37.94% examples, 1724776 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:51,880 : INFO : EPOCH 12 - PROGRESS: at 45.59% examples, 1733737 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:52,884 : INFO : EPOCH 12 - PROGRESS: at 53.16% examples, 1737803 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:53,897 : INFO : EPOCH 12 - PROGRESS: at 60.86% examples, 1741661 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:54,902 : INFO : EPOCH 12 - PROGRESS: at 68.57% examples, 1744208 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:10:55,912 : INFO : EPOCH 12 - PROGRESS: at 76.22% examples, 1740438 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:56,917 : INFO : EPOCH 12 - PROGRESS: at 83.76% examples, 1739675 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:57,919 : INFO : EPOCH 12 - PROGRESS: at 91.37% examples, 1739845 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:58,924 : INFO : EPOCH 12 - PROGRESS: at 99.05% examples, 1740207 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:10:59,014 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:10:59,027 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:10:59,030 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:10:59,031 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:10:59,033 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:10:59,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:10:59,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:10:59,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:10:59,044 : INFO : EPOCH - 12 : training on 23279529 raw words (22951015 effective words) took 13.2s, 1741326 effective words/s\n",
      "2020-01-08 21:11:00,051 : INFO : EPOCH 13 - PROGRESS: at 7.57% examples, 1716637 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:01,055 : INFO : EPOCH 13 - PROGRESS: at 15.26% examples, 1736755 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:02,059 : INFO : EPOCH 13 - PROGRESS: at 22.91% examples, 1745515 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:03,063 : INFO : EPOCH 13 - PROGRESS: at 30.66% examples, 1743113 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:04,067 : INFO : EPOCH 13 - PROGRESS: at 38.29% examples, 1738777 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:05,075 : INFO : EPOCH 13 - PROGRESS: at 45.74% examples, 1737028 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:06,077 : INFO : EPOCH 13 - PROGRESS: at 53.29% examples, 1739774 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:07,078 : INFO : EPOCH 13 - PROGRESS: at 60.90% examples, 1743563 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:08,082 : INFO : EPOCH 13 - PROGRESS: at 68.57% examples, 1744976 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:09,082 : INFO : EPOCH 13 - PROGRESS: at 76.27% examples, 1743761 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:10,084 : INFO : EPOCH 13 - PROGRESS: at 83.93% examples, 1745710 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:11,085 : INFO : EPOCH 13 - PROGRESS: at 91.62% examples, 1747264 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:12,092 : INFO : EPOCH 13 - PROGRESS: at 99.24% examples, 1746135 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:11:12,162 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:11:12,167 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:11:12,171 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:11:12,173 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:11:12,175 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:11:12,176 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:11:12,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:11:12,187 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:11:12,187 : INFO : EPOCH - 13 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1746736 effective words/s\n",
      "2020-01-08 21:11:13,196 : INFO : EPOCH 14 - PROGRESS: at 7.40% examples, 1674852 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:11:14,198 : INFO : EPOCH 14 - PROGRESS: at 15.02% examples, 1708635 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:15,198 : INFO : EPOCH 14 - PROGRESS: at 22.78% examples, 1737944 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:16,199 : INFO : EPOCH 14 - PROGRESS: at 30.39% examples, 1731805 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:17,204 : INFO : EPOCH 14 - PROGRESS: at 38.05% examples, 1729327 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:18,215 : INFO : EPOCH 14 - PROGRESS: at 45.64% examples, 1733246 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:19,220 : INFO : EPOCH 14 - PROGRESS: at 53.05% examples, 1731568 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:20,224 : INFO : EPOCH 14 - PROGRESS: at 60.52% examples, 1731982 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:21,239 : INFO : EPOCH 14 - PROGRESS: at 67.99% examples, 1728426 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:11:22,241 : INFO : EPOCH 14 - PROGRESS: at 75.64% examples, 1727478 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:23,251 : INFO : EPOCH 14 - PROGRESS: at 83.31% examples, 1728813 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:24,258 : INFO : EPOCH 14 - PROGRESS: at 90.95% examples, 1730226 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:25,258 : INFO : EPOCH 14 - PROGRESS: at 98.59% examples, 1731183 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:25,408 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:11:25,413 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:11:25,421 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:11:25,423 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:11:25,425 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:11:25,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:11:25,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:11:25,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:11:25,435 : INFO : EPOCH - 14 : training on 23279529 raw words (22951015 effective words) took 13.2s, 1733003 effective words/s\n",
      "2020-01-08 21:11:26,440 : INFO : EPOCH 15 - PROGRESS: at 7.52% examples, 1709731 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:11:27,441 : INFO : EPOCH 15 - PROGRESS: at 15.10% examples, 1721685 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:28,443 : INFO : EPOCH 15 - PROGRESS: at 22.54% examples, 1720020 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:29,455 : INFO : EPOCH 15 - PROGRESS: at 30.31% examples, 1723212 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:30,467 : INFO : EPOCH 15 - PROGRESS: at 38.04% examples, 1724079 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:31,473 : INFO : EPOCH 15 - PROGRESS: at 45.74% examples, 1734827 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:32,474 : INFO : EPOCH 15 - PROGRESS: at 53.41% examples, 1742192 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:33,477 : INFO : EPOCH 15 - PROGRESS: at 61.02% examples, 1745277 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:34,484 : INFO : EPOCH 15 - PROGRESS: at 68.70% examples, 1745888 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:35,487 : INFO : EPOCH 15 - PROGRESS: at 76.35% examples, 1743238 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:36,508 : INFO : EPOCH 15 - PROGRESS: at 84.01% examples, 1742342 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:37,512 : INFO : EPOCH 15 - PROGRESS: at 91.75% examples, 1744408 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:38,515 : INFO : EPOCH 15 - PROGRESS: at 99.52% examples, 1746979 words/s, in_qsize 11, out_qsize 0\n",
      "2020-01-08 21:11:38,543 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:11:38,547 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:11:38,551 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:11:38,555 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:11:38,556 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:11:38,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:11:38,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:11:38,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:11:38,570 : INFO : EPOCH - 15 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1747721 effective words/s\n",
      "2020-01-08 21:11:39,580 : INFO : EPOCH 16 - PROGRESS: at 7.65% examples, 1732708 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:40,584 : INFO : EPOCH 16 - PROGRESS: at 15.35% examples, 1744226 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:41,584 : INFO : EPOCH 16 - PROGRESS: at 23.00% examples, 1752404 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:42,589 : INFO : EPOCH 16 - PROGRESS: at 30.66% examples, 1743463 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:43,603 : INFO : EPOCH 16 - PROGRESS: at 38.29% examples, 1735545 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:44,605 : INFO : EPOCH 16 - PROGRESS: at 45.77% examples, 1737549 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:45,606 : INFO : EPOCH 16 - PROGRESS: at 53.41% examples, 1743260 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:46,607 : INFO : EPOCH 16 - PROGRESS: at 60.93% examples, 1744076 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:47,608 : INFO : EPOCH 16 - PROGRESS: at 68.66% examples, 1747163 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:48,615 : INFO : EPOCH 16 - PROGRESS: at 76.43% examples, 1746492 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:11:49,617 : INFO : EPOCH 16 - PROGRESS: at 84.06% examples, 1747432 words/s, in_qsize 15, out_qsize 1\n",
      "2020-01-08 21:11:50,634 : INFO : EPOCH 16 - PROGRESS: at 91.74% examples, 1746396 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:51,638 : INFO : EPOCH 16 - PROGRESS: at 99.37% examples, 1745634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:51,683 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:11:51,689 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:11:51,694 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:11:51,697 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:11:51,698 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:11:51,699 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:11:51,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:11:51,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:11:51,706 : INFO : EPOCH - 16 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1747666 effective words/s\n",
      "2020-01-08 21:11:52,712 : INFO : EPOCH 17 - PROGRESS: at 7.52% examples, 1710252 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:53,719 : INFO : EPOCH 17 - PROGRESS: at 15.19% examples, 1726292 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:11:54,727 : INFO : EPOCH 17 - PROGRESS: at 22.82% examples, 1735410 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:55,736 : INFO : EPOCH 17 - PROGRESS: at 30.71% examples, 1741097 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:56,737 : INFO : EPOCH 17 - PROGRESS: at 38.41% examples, 1742188 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:11:57,744 : INFO : EPOCH 17 - PROGRESS: at 45.99% examples, 1744642 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:11:58,753 : INFO : EPOCH 17 - PROGRESS: at 53.48% examples, 1743133 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:11:59,754 : INFO : EPOCH 17 - PROGRESS: at 61.06% examples, 1745453 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:00,754 : INFO : EPOCH 17 - PROGRESS: at 68.70% examples, 1746271 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:01,757 : INFO : EPOCH 17 - PROGRESS: at 76.47% examples, 1746542 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:02,760 : INFO : EPOCH 17 - PROGRESS: at 84.17% examples, 1748979 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:03,762 : INFO : EPOCH 17 - PROGRESS: at 91.79% examples, 1748458 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:12:04,768 : INFO : EPOCH 17 - PROGRESS: at 99.49% examples, 1748771 words/s, in_qsize 12, out_qsize 0\n",
      "2020-01-08 21:12:04,800 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:12:04,805 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:12:04,808 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:12:04,812 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:12:04,816 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:12:04,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:12:04,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:12:04,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:12:04,826 : INFO : EPOCH - 17 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1749933 effective words/s\n",
      "2020-01-08 21:12:05,831 : INFO : EPOCH 18 - PROGRESS: at 7.52% examples, 1710350 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:06,837 : INFO : EPOCH 18 - PROGRESS: at 15.05% examples, 1712976 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:07,841 : INFO : EPOCH 18 - PROGRESS: at 22.65% examples, 1725607 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:08,847 : INFO : EPOCH 18 - PROGRESS: at 30.43% examples, 1730407 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:09,861 : INFO : EPOCH 18 - PROGRESS: at 38.29% examples, 1734666 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:10,862 : INFO : EPOCH 18 - PROGRESS: at 45.91% examples, 1741836 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:11,867 : INFO : EPOCH 18 - PROGRESS: at 53.52% examples, 1745913 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:12,869 : INFO : EPOCH 18 - PROGRESS: at 61.18% examples, 1749954 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:12:13,869 : INFO : EPOCH 18 - PROGRESS: at 68.86% examples, 1751333 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:14,875 : INFO : EPOCH 18 - PROGRESS: at 76.42% examples, 1745753 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:12:15,884 : INFO : EPOCH 18 - PROGRESS: at 84.00% examples, 1744752 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:12:16,884 : INFO : EPOCH 18 - PROGRESS: at 91.70% examples, 1746416 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:17,891 : INFO : EPOCH 18 - PROGRESS: at 99.45% examples, 1747477 words/s, in_qsize 13, out_qsize 0\n",
      "2020-01-08 21:12:17,921 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:12:17,926 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:12:17,937 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:12:17,940 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:12:17,945 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:12:17,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:12:17,951 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:12:17,952 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:12:17,952 : INFO : EPOCH - 18 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1748977 effective words/s\n",
      "2020-01-08 21:12:18,963 : INFO : EPOCH 19 - PROGRESS: at 7.65% examples, 1733065 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:19,970 : INFO : EPOCH 19 - PROGRESS: at 15.33% examples, 1741905 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:20,979 : INFO : EPOCH 19 - PROGRESS: at 23.12% examples, 1755324 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:21,991 : INFO : EPOCH 19 - PROGRESS: at 30.83% examples, 1744810 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:22,993 : INFO : EPOCH 19 - PROGRESS: at 38.45% examples, 1740796 words/s, in_qsize 13, out_qsize 2\n",
      "2020-01-08 21:12:24,000 : INFO : EPOCH 19 - PROGRESS: at 45.95% examples, 1740538 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:25,003 : INFO : EPOCH 19 - PROGRESS: at 53.57% examples, 1745103 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:26,004 : INFO : EPOCH 19 - PROGRESS: at 61.26% examples, 1750635 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:27,005 : INFO : EPOCH 19 - PROGRESS: at 68.94% examples, 1751984 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:28,012 : INFO : EPOCH 19 - PROGRESS: at 76.73% examples, 1750971 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:29,018 : INFO : EPOCH 19 - PROGRESS: at 84.34% examples, 1750742 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:30,027 : INFO : EPOCH 19 - PROGRESS: at 91.98% examples, 1749787 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:31,030 : INFO : EPOCH 19 - PROGRESS: at 99.62% examples, 1749016 words/s, in_qsize 9, out_qsize 0\n",
      "2020-01-08 21:12:31,047 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:12:31,055 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:12:31,059 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:12:31,063 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:12:31,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:12:31,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:12:31,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:12:31,075 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:12:31,076 : INFO : EPOCH - 19 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1749542 effective words/s\n",
      "2020-01-08 21:12:32,081 : INFO : EPOCH 20 - PROGRESS: at 7.61% examples, 1729801 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:33,082 : INFO : EPOCH 20 - PROGRESS: at 15.26% examples, 1741488 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:34,082 : INFO : EPOCH 20 - PROGRESS: at 22.91% examples, 1750120 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:35,084 : INFO : EPOCH 20 - PROGRESS: at 30.71% examples, 1750408 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:36,088 : INFO : EPOCH 20 - PROGRESS: at 38.37% examples, 1746609 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:37,089 : INFO : EPOCH 20 - PROGRESS: at 45.99% examples, 1751781 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:38,089 : INFO : EPOCH 20 - PROGRESS: at 53.41% examples, 1748737 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:39,095 : INFO : EPOCH 20 - PROGRESS: at 60.93% examples, 1747924 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:12:40,102 : INFO : EPOCH 20 - PROGRESS: at 68.62% examples, 1748371 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:41,105 : INFO : EPOCH 20 - PROGRESS: at 76.43% examples, 1749191 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:42,109 : INFO : EPOCH 20 - PROGRESS: at 84.06% examples, 1749453 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:43,110 : INFO : EPOCH 20 - PROGRESS: at 91.74% examples, 1750739 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:44,113 : INFO : EPOCH 20 - PROGRESS: at 99.41% examples, 1750510 words/s, in_qsize 14, out_qsize 0\n",
      "2020-01-08 21:12:44,152 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:12:44,158 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:12:44,163 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:12:44,165 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:12:44,167 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:12:44,168 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:12:44,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:12:44,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:12:44,177 : INFO : EPOCH - 20 : training on 23279529 raw words (22951015 effective words) took 13.1s, 1752289 effective words/s\n",
      "2020-01-08 21:12:44,178 : INFO : training on a 465590580 raw words (459020300 effective words) took 265.3s, 1730377 effective words/s\n",
      "2020-01-08 21:12:44,178 : INFO : training model with 8 workers on 265408 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:25.278376\n",
      "Training Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:12:45,188 : INFO : EPOCH 1 - PROGRESS: at 5.30% examples, 1208067 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:46,192 : INFO : EPOCH 1 - PROGRESS: at 11.05% examples, 1260218 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:47,195 : INFO : EPOCH 1 - PROGRESS: at 16.64% examples, 1260763 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:48,203 : INFO : EPOCH 1 - PROGRESS: at 22.15% examples, 1264619 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:49,207 : INFO : EPOCH 1 - PROGRESS: at 27.85% examples, 1270136 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:50,209 : INFO : EPOCH 1 - PROGRESS: at 33.58% examples, 1271468 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:51,213 : INFO : EPOCH 1 - PROGRESS: at 39.36% examples, 1278899 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:52,222 : INFO : EPOCH 1 - PROGRESS: at 45.05% examples, 1282185 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:53,232 : INFO : EPOCH 1 - PROGRESS: at 50.78% examples, 1286661 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:54,235 : INFO : EPOCH 1 - PROGRESS: at 56.40% examples, 1289993 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:55,249 : INFO : EPOCH 1 - PROGRESS: at 61.95% examples, 1287369 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:12:56,251 : INFO : EPOCH 1 - PROGRESS: at 67.33% examples, 1284042 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:57,267 : INFO : EPOCH 1 - PROGRESS: at 72.95% examples, 1280448 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:58,280 : INFO : EPOCH 1 - PROGRESS: at 78.62% examples, 1279970 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:12:59,289 : INFO : EPOCH 1 - PROGRESS: at 84.25% examples, 1280811 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:00,290 : INFO : EPOCH 1 - PROGRESS: at 90.02% examples, 1283216 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:01,293 : INFO : EPOCH 1 - PROGRESS: at 95.75% examples, 1284375 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:01,993 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:13:02,005 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:13:02,007 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:13:02,012 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:13:02,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:13:02,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:13:02,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:13:02,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:13:02,032 : INFO : EPOCH - 1 : training on 23279529 raw words (22951015 effective words) took 17.8s, 1286065 effective words/s\n",
      "2020-01-08 21:13:03,059 : INFO : EPOCH 2 - PROGRESS: at 5.65% examples, 1257582 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:04,064 : INFO : EPOCH 2 - PROGRESS: at 11.33% examples, 1279673 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:05,069 : INFO : EPOCH 2 - PROGRESS: at 17.13% examples, 1288743 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:06,078 : INFO : EPOCH 2 - PROGRESS: at 22.82% examples, 1295193 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:07,085 : INFO : EPOCH 2 - PROGRESS: at 28.60% examples, 1295933 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:08,089 : INFO : EPOCH 2 - PROGRESS: at 34.37% examples, 1295726 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:09,100 : INFO : EPOCH 2 - PROGRESS: at 40.12% examples, 1296784 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:10,103 : INFO : EPOCH 2 - PROGRESS: at 45.86% examples, 1301307 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:11,112 : INFO : EPOCH 2 - PROGRESS: at 51.52% examples, 1301565 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:12,114 : INFO : EPOCH 2 - PROGRESS: at 57.11% examples, 1302574 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:13,114 : INFO : EPOCH 2 - PROGRESS: at 62.76% examples, 1302219 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:14,116 : INFO : EPOCH 2 - PROGRESS: at 68.47% examples, 1303289 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:15,122 : INFO : EPOCH 2 - PROGRESS: at 74.17% examples, 1301450 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:16,129 : INFO : EPOCH 2 - PROGRESS: at 79.81% examples, 1298783 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:17,134 : INFO : EPOCH 2 - PROGRESS: at 85.21% examples, 1296048 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:18,155 : INFO : EPOCH 2 - PROGRESS: at 90.74% examples, 1292204 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:19,164 : INFO : EPOCH 2 - PROGRESS: at 96.57% examples, 1294106 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:19,718 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:13:19,726 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:13:19,729 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:13:19,734 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:13:19,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:13:19,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:13:19,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:13:19,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:13:19,753 : INFO : EPOCH - 2 : training on 23279529 raw words (22951015 effective words) took 17.7s, 1295411 effective words/s\n",
      "2020-01-08 21:13:20,776 : INFO : EPOCH 3 - PROGRESS: at 5.65% examples, 1263146 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:21,777 : INFO : EPOCH 3 - PROGRESS: at 11.41% examples, 1294648 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:22,778 : INFO : EPOCH 3 - PROGRESS: at 17.21% examples, 1300207 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:23,785 : INFO : EPOCH 3 - PROGRESS: at 22.87% examples, 1302331 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:24,786 : INFO : EPOCH 3 - PROGRESS: at 28.60% examples, 1301160 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:25,789 : INFO : EPOCH 3 - PROGRESS: at 34.46% examples, 1303598 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:26,790 : INFO : EPOCH 3 - PROGRESS: at 40.12% examples, 1302585 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:27,790 : INFO : EPOCH 3 - PROGRESS: at 45.86% examples, 1306738 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:28,790 : INFO : EPOCH 3 - PROGRESS: at 51.48% examples, 1306711 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:29,793 : INFO : EPOCH 3 - PROGRESS: at 57.11% examples, 1308120 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:30,809 : INFO : EPOCH 3 - PROGRESS: at 62.92% examples, 1308881 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:31,811 : INFO : EPOCH 3 - PROGRESS: at 68.66% examples, 1309356 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:32,815 : INFO : EPOCH 3 - PROGRESS: at 74.47% examples, 1309479 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:33,816 : INFO : EPOCH 3 - PROGRESS: at 80.30% examples, 1310066 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:34,842 : INFO : EPOCH 3 - PROGRESS: at 85.97% examples, 1308666 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:35,848 : INFO : EPOCH 3 - PROGRESS: at 91.74% examples, 1308898 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:36,857 : INFO : EPOCH 3 - PROGRESS: at 97.60% examples, 1309855 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:37,229 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:13:37,238 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:13:37,247 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:13:37,248 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:13:37,249 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:13:37,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:13:37,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:13:37,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:13:37,264 : INFO : EPOCH - 3 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1310964 effective words/s\n",
      "2020-01-08 21:13:38,293 : INFO : EPOCH 4 - PROGRESS: at 5.65% examples, 1255604 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:39,297 : INFO : EPOCH 4 - PROGRESS: at 11.45% examples, 1293342 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:40,309 : INFO : EPOCH 4 - PROGRESS: at 17.29% examples, 1297912 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:41,310 : INFO : EPOCH 4 - PROGRESS: at 23.00% examples, 1304797 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:42,316 : INFO : EPOCH 4 - PROGRESS: at 28.73% examples, 1301936 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:43,330 : INFO : EPOCH 4 - PROGRESS: at 34.50% examples, 1298700 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:44,337 : INFO : EPOCH 4 - PROGRESS: at 40.16% examples, 1297165 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:45,352 : INFO : EPOCH 4 - PROGRESS: at 45.95% examples, 1300888 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:46,369 : INFO : EPOCH 4 - PROGRESS: at 51.72% examples, 1303236 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:47,375 : INFO : EPOCH 4 - PROGRESS: at 57.48% examples, 1307475 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:48,390 : INFO : EPOCH 4 - PROGRESS: at 63.39% examples, 1310291 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:49,393 : INFO : EPOCH 4 - PROGRESS: at 69.10% examples, 1310476 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:50,404 : INFO : EPOCH 4 - PROGRESS: at 74.95% examples, 1309785 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:51,408 : INFO : EPOCH 4 - PROGRESS: at 80.58% examples, 1307295 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:52,410 : INFO : EPOCH 4 - PROGRESS: at 86.05% examples, 1305074 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:53,412 : INFO : EPOCH 4 - PROGRESS: at 91.74% examples, 1304588 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:54,428 : INFO : EPOCH 4 - PROGRESS: at 97.60% examples, 1305247 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:54,793 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:13:54,803 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:13:54,806 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:13:54,810 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:13:54,815 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:13:54,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:13:54,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:13:54,831 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:13:54,831 : INFO : EPOCH - 4 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1306721 effective words/s\n",
      "2020-01-08 21:13:55,868 : INFO : EPOCH 5 - PROGRESS: at 5.65% examples, 1246123 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:56,869 : INFO : EPOCH 5 - PROGRESS: at 11.45% examples, 1290760 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:13:57,869 : INFO : EPOCH 5 - PROGRESS: at 17.20% examples, 1294750 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:58,871 : INFO : EPOCH 5 - PROGRESS: at 22.82% examples, 1297368 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:13:59,872 : INFO : EPOCH 5 - PROGRESS: at 28.60% examples, 1299141 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:00,880 : INFO : EPOCH 5 - PROGRESS: at 34.50% examples, 1302307 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:01,900 : INFO : EPOCH 5 - PROGRESS: at 40.30% examples, 1302316 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:02,907 : INFO : EPOCH 5 - PROGRESS: at 46.03% examples, 1305348 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:03,924 : INFO : EPOCH 5 - PROGRESS: at 51.72% examples, 1305062 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:04,941 : INFO : EPOCH 5 - PROGRESS: at 57.40% examples, 1305747 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:05,943 : INFO : EPOCH 5 - PROGRESS: at 63.17% examples, 1307590 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:06,953 : INFO : EPOCH 5 - PROGRESS: at 68.94% examples, 1308058 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:07,960 : INFO : EPOCH 5 - PROGRESS: at 74.78% examples, 1308024 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:08,961 : INFO : EPOCH 5 - PROGRESS: at 80.50% examples, 1307258 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:09,962 : INFO : EPOCH 5 - PROGRESS: at 86.25% examples, 1309634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:10,976 : INFO : EPOCH 5 - PROGRESS: at 91.99% examples, 1308441 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:11,981 : INFO : EPOCH 5 - PROGRESS: at 97.60% examples, 1306393 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:12,361 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:14:12,367 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:14:12,368 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:14:12,378 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:14:12,380 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:14:12,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:14:12,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:14:12,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:14:12,393 : INFO : EPOCH - 5 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1307147 effective words/s\n",
      "2020-01-08 21:14:13,415 : INFO : EPOCH 6 - PROGRESS: at 5.65% examples, 1264592 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:14,423 : INFO : EPOCH 6 - PROGRESS: at 11.33% examples, 1281151 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:15,427 : INFO : EPOCH 6 - PROGRESS: at 17.13% examples, 1290008 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:16,435 : INFO : EPOCH 6 - PROGRESS: at 22.86% examples, 1299214 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:17,444 : INFO : EPOCH 6 - PROGRESS: at 28.91% examples, 1310011 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:18,447 : INFO : EPOCH 6 - PROGRESS: at 34.66% examples, 1307864 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:19,447 : INFO : EPOCH 6 - PROGRESS: at 40.42% examples, 1309161 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:20,452 : INFO : EPOCH 6 - PROGRESS: at 45.99% examples, 1306860 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:21,455 : INFO : EPOCH 6 - PROGRESS: at 51.59% examples, 1306417 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:22,457 : INFO : EPOCH 6 - PROGRESS: at 57.19% examples, 1306980 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:23,457 : INFO : EPOCH 6 - PROGRESS: at 62.92% examples, 1307912 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:24,462 : INFO : EPOCH 6 - PROGRESS: at 68.62% examples, 1307362 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:25,463 : INFO : EPOCH 6 - PROGRESS: at 74.42% examples, 1307941 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:26,464 : INFO : EPOCH 6 - PROGRESS: at 80.13% examples, 1306684 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:27,469 : INFO : EPOCH 6 - PROGRESS: at 85.89% examples, 1308578 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:28,479 : INFO : EPOCH 6 - PROGRESS: at 91.62% examples, 1307894 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:29,490 : INFO : EPOCH 6 - PROGRESS: at 97.35% examples, 1307059 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:29,899 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:14:29,908 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:14:29,912 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:14:29,916 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:14:29,918 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:14:29,923 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:14:29,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:14:29,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:14:29,936 : INFO : EPOCH - 6 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1308627 effective words/s\n",
      "2020-01-08 21:14:30,966 : INFO : EPOCH 7 - PROGRESS: at 5.65% examples, 1253238 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:31,968 : INFO : EPOCH 7 - PROGRESS: at 11.50% examples, 1298563 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:32,969 : INFO : EPOCH 7 - PROGRESS: at 17.29% examples, 1302776 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:33,975 : INFO : EPOCH 7 - PROGRESS: at 22.86% examples, 1299634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:34,982 : INFO : EPOCH 7 - PROGRESS: at 28.69% examples, 1301469 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:35,982 : INFO : EPOCH 7 - PROGRESS: at 34.37% examples, 1297921 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:36,993 : INFO : EPOCH 7 - PROGRESS: at 40.10% examples, 1298733 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:37,998 : INFO : EPOCH 7 - PROGRESS: at 45.91% examples, 1303861 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:39,003 : INFO : EPOCH 7 - PROGRESS: at 51.52% examples, 1303458 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:40,009 : INFO : EPOCH 7 - PROGRESS: at 57.20% examples, 1305700 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:41,017 : INFO : EPOCH 7 - PROGRESS: at 62.96% examples, 1306737 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:42,020 : INFO : EPOCH 7 - PROGRESS: at 68.62% examples, 1305710 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:43,020 : INFO : EPOCH 7 - PROGRESS: at 74.25% examples, 1303500 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:44,028 : INFO : EPOCH 7 - PROGRESS: at 80.01% examples, 1302599 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:45,034 : INFO : EPOCH 7 - PROGRESS: at 85.63% examples, 1302756 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:46,036 : INFO : EPOCH 7 - PROGRESS: at 91.41% examples, 1303575 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:47,039 : INFO : EPOCH 7 - PROGRESS: at 97.26% examples, 1305343 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:47,463 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:14:47,468 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:14:47,470 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:14:47,477 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:14:47,481 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:14:47,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:14:47,486 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:14:47,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:14:47,496 : INFO : EPOCH - 7 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1307264 effective words/s\n",
      "2020-01-08 21:14:48,503 : INFO : EPOCH 8 - PROGRESS: at 5.65% examples, 1282069 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:49,518 : INFO : EPOCH 8 - PROGRESS: at 11.29% examples, 1281093 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:50,521 : INFO : EPOCH 8 - PROGRESS: at 17.09% examples, 1290597 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:51,534 : INFO : EPOCH 8 - PROGRESS: at 22.82% examples, 1297688 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:52,538 : INFO : EPOCH 8 - PROGRESS: at 28.56% examples, 1296634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:53,541 : INFO : EPOCH 8 - PROGRESS: at 34.28% examples, 1295080 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:54,547 : INFO : EPOCH 8 - PROGRESS: at 40.02% examples, 1297020 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:55,553 : INFO : EPOCH 8 - PROGRESS: at 45.74% examples, 1299875 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:56,574 : INFO : EPOCH 8 - PROGRESS: at 51.52% examples, 1301822 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:57,574 : INFO : EPOCH 8 - PROGRESS: at 57.27% examples, 1306950 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:14:58,578 : INFO : EPOCH 8 - PROGRESS: at 62.92% examples, 1305749 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:14:59,585 : INFO : EPOCH 8 - PROGRESS: at 68.66% examples, 1305944 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:00,586 : INFO : EPOCH 8 - PROGRESS: at 74.47% examples, 1306656 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:01,594 : INFO : EPOCH 8 - PROGRESS: at 80.33% examples, 1307454 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:02,601 : INFO : EPOCH 8 - PROGRESS: at 85.97% examples, 1307293 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:03,602 : INFO : EPOCH 8 - PROGRESS: at 91.74% examples, 1307990 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:04,617 : INFO : EPOCH 8 - PROGRESS: at 97.60% examples, 1308531 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:04,985 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:15:04,995 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:15:05,000 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:15:05,005 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:15:05,008 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:15:05,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:15:05,015 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:15:05,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:15:05,023 : INFO : EPOCH - 8 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1309752 effective words/s\n",
      "2020-01-08 21:15:06,039 : INFO : EPOCH 9 - PROGRESS: at 5.65% examples, 1270925 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:07,041 : INFO : EPOCH 9 - PROGRESS: at 11.45% examples, 1302853 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:08,049 : INFO : EPOCH 9 - PROGRESS: at 17.29% examples, 1306260 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:09,056 : INFO : EPOCH 9 - PROGRESS: at 23.00% examples, 1309163 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:10,057 : INFO : EPOCH 9 - PROGRESS: at 28.87% examples, 1312443 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:11,063 : INFO : EPOCH 9 - PROGRESS: at 34.58% examples, 1307482 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:12,083 : INFO : EPOCH 9 - PROGRESS: at 40.46% examples, 1309237 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:13,102 : INFO : EPOCH 9 - PROGRESS: at 46.29% examples, 1311899 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:14,106 : INFO : EPOCH 9 - PROGRESS: at 51.97% examples, 1312732 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:15,110 : INFO : EPOCH 9 - PROGRESS: at 57.57% examples, 1312468 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:16,128 : INFO : EPOCH 9 - PROGRESS: at 63.27% examples, 1310089 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:15:17,130 : INFO : EPOCH 9 - PROGRESS: at 68.90% examples, 1308879 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:18,143 : INFO : EPOCH 9 - PROGRESS: at 74.47% examples, 1303690 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:19,145 : INFO : EPOCH 9 - PROGRESS: at 80.33% examples, 1305270 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:20,159 : INFO : EPOCH 9 - PROGRESS: at 85.97% examples, 1304584 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:21,160 : INFO : EPOCH 9 - PROGRESS: at 91.78% examples, 1306118 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:22,169 : INFO : EPOCH 9 - PROGRESS: at 97.72% examples, 1308331 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:22,509 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:15:22,516 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:15:22,525 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:15:22,529 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:15:22,532 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:15:22,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:15:22,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:15:22,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:15:22,546 : INFO : EPOCH - 9 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1310071 effective words/s\n",
      "2020-01-08 21:15:23,566 : INFO : EPOCH 10 - PROGRESS: at 5.65% examples, 1265890 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:24,568 : INFO : EPOCH 10 - PROGRESS: at 11.41% examples, 1295050 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:25,571 : INFO : EPOCH 10 - PROGRESS: at 17.16% examples, 1296552 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:26,573 : INFO : EPOCH 10 - PROGRESS: at 22.78% examples, 1298756 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:27,580 : INFO : EPOCH 10 - PROGRESS: at 28.42% examples, 1293026 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:28,581 : INFO : EPOCH 10 - PROGRESS: at 34.15% examples, 1292434 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:29,591 : INFO : EPOCH 10 - PROGRESS: at 39.92% examples, 1295416 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:30,595 : INFO : EPOCH 10 - PROGRESS: at 45.67% examples, 1298922 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:31,595 : INFO : EPOCH 10 - PROGRESS: at 51.44% examples, 1303917 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:32,596 : INFO : EPOCH 10 - PROGRESS: at 57.07% examples, 1305723 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:33,613 : INFO : EPOCH 10 - PROGRESS: at 62.92% examples, 1307523 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:34,617 : INFO : EPOCH 10 - PROGRESS: at 68.66% examples, 1307817 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:35,618 : INFO : EPOCH 10 - PROGRESS: at 74.47% examples, 1308412 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:36,632 : INFO : EPOCH 10 - PROGRESS: at 80.33% examples, 1308547 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:37,633 : INFO : EPOCH 10 - PROGRESS: at 85.97% examples, 1308840 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:38,633 : INFO : EPOCH 10 - PROGRESS: at 91.70% examples, 1308910 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:39,636 : INFO : EPOCH 10 - PROGRESS: at 97.47% examples, 1309171 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:40,031 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:15:40,041 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:15:40,044 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:15:40,050 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:15:40,054 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:15:40,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:15:40,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:15:40,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:15:40,068 : INFO : EPOCH - 10 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1310101 effective words/s\n",
      "2020-01-08 21:15:41,088 : INFO : EPOCH 11 - PROGRESS: at 5.65% examples, 1266177 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:42,095 : INFO : EPOCH 11 - PROGRESS: at 11.50% examples, 1302203 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:43,111 : INFO : EPOCH 11 - PROGRESS: at 17.38% examples, 1305162 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:44,111 : INFO : EPOCH 11 - PROGRESS: at 23.04% examples, 1308212 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:45,129 : INFO : EPOCH 11 - PROGRESS: at 28.91% examples, 1307196 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:46,133 : INFO : EPOCH 11 - PROGRESS: at 34.70% examples, 1306800 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:47,133 : INFO : EPOCH 11 - PROGRESS: at 40.46% examples, 1308264 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:48,148 : INFO : EPOCH 11 - PROGRESS: at 46.29% examples, 1311835 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:49,170 : INFO : EPOCH 11 - PROGRESS: at 52.05% examples, 1312103 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:50,178 : INFO : EPOCH 11 - PROGRESS: at 57.78% examples, 1314287 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:15:51,185 : INFO : EPOCH 11 - PROGRESS: at 63.58% examples, 1315673 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:52,195 : INFO : EPOCH 11 - PROGRESS: at 69.37% examples, 1315486 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:53,204 : INFO : EPOCH 11 - PROGRESS: at 75.30% examples, 1316203 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:15:54,214 : INFO : EPOCH 11 - PROGRESS: at 81.08% examples, 1315335 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:55,218 : INFO : EPOCH 11 - PROGRESS: at 86.87% examples, 1316927 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:56,224 : INFO : EPOCH 11 - PROGRESS: at 92.66% examples, 1317118 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:57,235 : INFO : EPOCH 11 - PROGRESS: at 98.50% examples, 1316878 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:57,450 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:15:57,455 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:15:57,462 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:15:57,466 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:15:57,466 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:15:57,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:15:57,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:15:57,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:15:57,483 : INFO : EPOCH - 11 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1318186 effective words/s\n",
      "2020-01-08 21:15:58,520 : INFO : EPOCH 12 - PROGRESS: at 5.65% examples, 1244909 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:15:59,527 : INFO : EPOCH 12 - PROGRESS: at 11.45% examples, 1286350 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:00,536 : INFO : EPOCH 12 - PROGRESS: at 17.29% examples, 1294506 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:01,537 : INFO : EPOCH 12 - PROGRESS: at 23.04% examples, 1304413 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:02,543 : INFO : EPOCH 12 - PROGRESS: at 28.87% examples, 1305518 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:03,548 : INFO : EPOCH 12 - PROGRESS: at 34.50% examples, 1298710 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:04,553 : INFO : EPOCH 12 - PROGRESS: at 39.92% examples, 1290782 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:05,562 : INFO : EPOCH 12 - PROGRESS: at 45.33% examples, 1284428 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:06,572 : INFO : EPOCH 12 - PROGRESS: at 50.78% examples, 1281004 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:07,573 : INFO : EPOCH 12 - PROGRESS: at 56.09% examples, 1277565 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:08,585 : INFO : EPOCH 12 - PROGRESS: at 61.59% examples, 1276228 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:09,586 : INFO : EPOCH 12 - PROGRESS: at 67.03% examples, 1274808 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:10,587 : INFO : EPOCH 12 - PROGRESS: at 72.60% examples, 1272583 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:11,587 : INFO : EPOCH 12 - PROGRESS: at 78.19% examples, 1272462 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:12,591 : INFO : EPOCH 12 - PROGRESS: at 83.35% examples, 1266551 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:16:13,593 : INFO : EPOCH 12 - PROGRESS: at 88.76% examples, 1264935 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:14,601 : INFO : EPOCH 12 - PROGRESS: at 94.16% examples, 1263418 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:15,575 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:16:15,584 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:16:15,587 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:16:15,593 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:16:15,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:16:15,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:16:15,602 : INFO : EPOCH 12 - PROGRESS: at 99.96% examples, 1266402 words/s, in_qsize 1, out_qsize 1\n",
      "2020-01-08 21:16:15,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:16:15,611 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:16:15,612 : INFO : EPOCH - 12 : training on 23279529 raw words (22951015 effective words) took 18.1s, 1266241 effective words/s\n",
      "2020-01-08 21:16:16,632 : INFO : EPOCH 13 - PROGRESS: at 5.65% examples, 1265495 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:17,632 : INFO : EPOCH 13 - PROGRESS: at 11.54% examples, 1310858 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:18,645 : INFO : EPOCH 13 - PROGRESS: at 17.46% examples, 1315404 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:19,651 : INFO : EPOCH 13 - PROGRESS: at 23.33% examples, 1326007 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:20,655 : INFO : EPOCH 13 - PROGRESS: at 29.12% examples, 1321529 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:21,656 : INFO : EPOCH 13 - PROGRESS: at 34.67% examples, 1309701 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:22,664 : INFO : EPOCH 13 - PROGRESS: at 39.98% examples, 1295537 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:23,666 : INFO : EPOCH 13 - PROGRESS: at 45.17% examples, 1283567 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:24,667 : INFO : EPOCH 13 - PROGRESS: at 50.66% examples, 1282579 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:25,668 : INFO : EPOCH 13 - PROGRESS: at 56.20% examples, 1284810 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:26,675 : INFO : EPOCH 13 - PROGRESS: at 61.95% examples, 1287707 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:27,681 : INFO : EPOCH 13 - PROGRESS: at 67.80% examples, 1292762 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:28,685 : INFO : EPOCH 13 - PROGRESS: at 73.60% examples, 1292742 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:29,687 : INFO : EPOCH 13 - PROGRESS: at 79.44% examples, 1294439 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:30,688 : INFO : EPOCH 13 - PROGRESS: at 85.21% examples, 1298191 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:31,692 : INFO : EPOCH 13 - PROGRESS: at 91.00% examples, 1299235 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:32,696 : INFO : EPOCH 13 - PROGRESS: at 96.75% examples, 1299953 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:33,221 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:16:33,232 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:16:33,233 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:16:33,241 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:16:33,242 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:16:33,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:16:33,247 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:16:33,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:16:33,257 : INFO : EPOCH - 13 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1300970 effective words/s\n",
      "2020-01-08 21:16:34,282 : INFO : EPOCH 14 - PROGRESS: at 5.65% examples, 1260125 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:35,283 : INFO : EPOCH 14 - PROGRESS: at 11.45% examples, 1297963 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:36,285 : INFO : EPOCH 14 - PROGRESS: at 17.33% examples, 1308266 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:37,286 : INFO : EPOCH 14 - PROGRESS: at 23.09% examples, 1315044 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:38,300 : INFO : EPOCH 14 - PROGRESS: at 28.91% examples, 1311919 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:39,305 : INFO : EPOCH 14 - PROGRESS: at 34.71% examples, 1310571 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:40,306 : INFO : EPOCH 14 - PROGRESS: at 40.50% examples, 1312697 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:41,318 : INFO : EPOCH 14 - PROGRESS: at 46.29% examples, 1314844 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:42,332 : INFO : EPOCH 14 - PROGRESS: at 52.05% examples, 1315926 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:43,338 : INFO : EPOCH 14 - PROGRESS: at 57.79% examples, 1318042 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:44,339 : INFO : EPOCH 14 - PROGRESS: at 63.42% examples, 1316340 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:45,343 : INFO : EPOCH 14 - PROGRESS: at 69.25% examples, 1317545 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:46,350 : INFO : EPOCH 14 - PROGRESS: at 75.11% examples, 1317511 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:47,352 : INFO : EPOCH 14 - PROGRESS: at 80.96% examples, 1317983 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:48,368 : INFO : EPOCH 14 - PROGRESS: at 86.65% examples, 1317009 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:49,369 : INFO : EPOCH 14 - PROGRESS: at 92.45% examples, 1317660 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:50,369 : INFO : EPOCH 14 - PROGRESS: at 98.10% examples, 1316024 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:50,653 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:16:50,664 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:16:50,665 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:16:50,673 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:16:50,674 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:16:50,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:16:50,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:16:50,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:16:50,691 : INFO : EPOCH - 14 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1316713 effective words/s\n",
      "2020-01-08 21:16:51,715 : INFO : EPOCH 15 - PROGRESS: at 5.65% examples, 1261207 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:52,719 : INFO : EPOCH 15 - PROGRESS: at 11.50% examples, 1301899 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:53,720 : INFO : EPOCH 15 - PROGRESS: at 17.33% examples, 1308194 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:54,735 : INFO : EPOCH 15 - PROGRESS: at 23.16% examples, 1315296 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:55,740 : INFO : EPOCH 15 - PROGRESS: at 29.15% examples, 1322068 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:56,741 : INFO : EPOCH 15 - PROGRESS: at 34.98% examples, 1319836 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:16:57,743 : INFO : EPOCH 15 - PROGRESS: at 40.67% examples, 1317753 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:58,763 : INFO : EPOCH 15 - PROGRESS: at 46.29% examples, 1313075 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:16:59,784 : INFO : EPOCH 15 - PROGRESS: at 52.05% examples, 1313453 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:00,786 : INFO : EPOCH 15 - PROGRESS: at 57.79% examples, 1316264 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:01,797 : INFO : EPOCH 15 - PROGRESS: at 63.58% examples, 1317063 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:02,802 : INFO : EPOCH 15 - PROGRESS: at 69.39% examples, 1317279 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:17:03,803 : INFO : EPOCH 15 - PROGRESS: at 75.20% examples, 1317151 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:04,809 : INFO : EPOCH 15 - PROGRESS: at 81.00% examples, 1316580 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:05,809 : INFO : EPOCH 15 - PROGRESS: at 86.65% examples, 1316480 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:06,819 : INFO : EPOCH 15 - PROGRESS: at 92.57% examples, 1318209 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:07,821 : INFO : EPOCH 15 - PROGRESS: at 98.32% examples, 1317477 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:08,060 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:17:08,067 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:17:08,070 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:17:08,075 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:17:08,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:17:08,083 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:17:08,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:17:08,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:17:08,095 : INFO : EPOCH - 15 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1319035 effective words/s\n",
      "2020-01-08 21:17:09,116 : INFO : EPOCH 16 - PROGRESS: at 5.65% examples, 1264669 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:10,117 : INFO : EPOCH 16 - PROGRESS: at 11.50% examples, 1305025 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:11,130 : INFO : EPOCH 16 - PROGRESS: at 17.38% examples, 1308610 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:17:12,148 : INFO : EPOCH 16 - PROGRESS: at 23.16% examples, 1311989 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:13,151 : INFO : EPOCH 16 - PROGRESS: at 29.04% examples, 1314324 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:14,157 : INFO : EPOCH 16 - PROGRESS: at 34.86% examples, 1312281 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:15,160 : INFO : EPOCH 16 - PROGRESS: at 40.59% examples, 1312472 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:16,163 : INFO : EPOCH 16 - PROGRESS: at 46.20% examples, 1311386 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:17,164 : INFO : EPOCH 16 - PROGRESS: at 51.77% examples, 1309507 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:18,171 : INFO : EPOCH 16 - PROGRESS: at 57.40% examples, 1310132 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:19,187 : INFO : EPOCH 16 - PROGRESS: at 63.27% examples, 1311621 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:20,196 : INFO : EPOCH 16 - PROGRESS: at 69.07% examples, 1312691 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:21,205 : INFO : EPOCH 16 - PROGRESS: at 74.99% examples, 1313532 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:22,208 : INFO : EPOCH 16 - PROGRESS: at 80.78% examples, 1313569 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:23,240 : INFO : EPOCH 16 - PROGRESS: at 86.65% examples, 1314077 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:24,246 : INFO : EPOCH 16 - PROGRESS: at 92.57% examples, 1316317 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:25,252 : INFO : EPOCH 16 - PROGRESS: at 98.27% examples, 1314847 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:25,503 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:17:25,509 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:17:25,511 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:17:25,518 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:17:25,519 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:17:25,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:17:25,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:17:25,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:17:25,538 : INFO : EPOCH - 16 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1316055 effective words/s\n",
      "2020-01-08 21:17:26,558 : INFO : EPOCH 17 - PROGRESS: at 5.65% examples, 1265575 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:27,559 : INFO : EPOCH 17 - PROGRESS: at 11.45% examples, 1301115 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:28,559 : INFO : EPOCH 17 - PROGRESS: at 17.16% examples, 1298601 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:29,563 : INFO : EPOCH 17 - PROGRESS: at 22.86% examples, 1304280 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:30,576 : INFO : EPOCH 17 - PROGRESS: at 28.56% examples, 1297791 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:31,587 : INFO : EPOCH 17 - PROGRESS: at 34.24% examples, 1292659 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:32,592 : INFO : EPOCH 17 - PROGRESS: at 40.06% examples, 1297952 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:33,601 : INFO : EPOCH 17 - PROGRESS: at 45.95% examples, 1304880 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:34,605 : INFO : EPOCH 17 - PROGRESS: at 51.72% examples, 1308679 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:35,607 : INFO : EPOCH 17 - PROGRESS: at 57.40% examples, 1311033 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:36,612 : INFO : EPOCH 17 - PROGRESS: at 63.18% examples, 1311979 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:37,618 : INFO : EPOCH 17 - PROGRESS: at 68.74% examples, 1308555 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:38,618 : INFO : EPOCH 17 - PROGRESS: at 74.56% examples, 1309158 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:39,636 : INFO : EPOCH 17 - PROGRESS: at 80.37% examples, 1308163 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:40,639 : INFO : EPOCH 17 - PROGRESS: at 86.22% examples, 1311450 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:17:41,649 : INFO : EPOCH 17 - PROGRESS: at 91.99% examples, 1311139 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:42,650 : INFO : EPOCH 17 - PROGRESS: at 97.85% examples, 1312624 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:42,988 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:17:42,991 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:17:42,993 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:17:43,003 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:17:43,005 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:17:43,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:17:43,014 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:17:43,019 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:17:43,020 : INFO : EPOCH - 17 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1313126 effective words/s\n",
      "2020-01-08 21:17:44,025 : INFO : EPOCH 18 - PROGRESS: at 5.49% examples, 1246632 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:45,031 : INFO : EPOCH 18 - PROGRESS: at 11.05% examples, 1259195 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:46,049 : INFO : EPOCH 18 - PROGRESS: at 16.80% examples, 1266520 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:47,054 : INFO : EPOCH 18 - PROGRESS: at 22.49% examples, 1279563 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:48,059 : INFO : EPOCH 18 - PROGRESS: at 28.19% examples, 1281939 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:49,064 : INFO : EPOCH 18 - PROGRESS: at 34.02% examples, 1285486 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:50,067 : INFO : EPOCH 18 - PROGRESS: at 39.81% examples, 1290938 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:51,092 : INFO : EPOCH 18 - PROGRESS: at 45.64% examples, 1293917 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:52,093 : INFO : EPOCH 18 - PROGRESS: at 51.40% examples, 1299337 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:53,096 : INFO : EPOCH 18 - PROGRESS: at 57.11% examples, 1303363 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:17:54,111 : INFO : EPOCH 18 - PROGRESS: at 62.92% examples, 1304607 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:55,116 : INFO : EPOCH 18 - PROGRESS: at 68.70% examples, 1305921 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:56,116 : INFO : EPOCH 18 - PROGRESS: at 74.56% examples, 1307468 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:57,130 : INFO : EPOCH 18 - PROGRESS: at 80.37% examples, 1306976 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:17:58,148 : INFO : EPOCH 18 - PROGRESS: at 85.97% examples, 1305288 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:17:59,149 : INFO : EPOCH 18 - PROGRESS: at 91.74% examples, 1306101 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:00,162 : INFO : EPOCH 18 - PROGRESS: at 97.60% examples, 1306886 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:00,530 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:18:00,537 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:18:00,539 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:18:00,547 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:18:00,549 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:18:00,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:18:00,557 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:18:00,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:18:00,564 : INFO : EPOCH - 18 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1308428 effective words/s\n",
      "2020-01-08 21:18:01,585 : INFO : EPOCH 19 - PROGRESS: at 5.65% examples, 1264528 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:02,588 : INFO : EPOCH 19 - PROGRESS: at 11.45% examples, 1299092 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:03,592 : INFO : EPOCH 19 - PROGRESS: at 17.29% examples, 1305259 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:04,594 : INFO : EPOCH 19 - PROGRESS: at 22.95% examples, 1307631 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:05,594 : INFO : EPOCH 19 - PROGRESS: at 28.78% examples, 1309508 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:06,599 : INFO : EPOCH 19 - PROGRESS: at 34.58% examples, 1308583 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:07,601 : INFO : EPOCH 19 - PROGRESS: at 40.42% examples, 1312250 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:08,602 : INFO : EPOCH 19 - PROGRESS: at 46.16% examples, 1314932 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:09,608 : INFO : EPOCH 19 - PROGRESS: at 51.85% examples, 1315198 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:10,615 : INFO : EPOCH 19 - PROGRESS: at 57.53% examples, 1316239 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:11,615 : INFO : EPOCH 19 - PROGRESS: at 63.34% examples, 1318267 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:12,619 : INFO : EPOCH 19 - PROGRESS: at 69.07% examples, 1317688 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:13,619 : INFO : EPOCH 19 - PROGRESS: at 74.95% examples, 1318322 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:14,625 : INFO : EPOCH 19 - PROGRESS: at 80.66% examples, 1316357 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:15,630 : INFO : EPOCH 19 - PROGRESS: at 86.33% examples, 1316529 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:16,631 : INFO : EPOCH 19 - PROGRESS: at 92.10% examples, 1316598 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:17,639 : INFO : EPOCH 19 - PROGRESS: at 97.98% examples, 1317188 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:17,939 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:18:17,949 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:18:17,951 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:18:17,958 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:18:17,959 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:18:17,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:18:17,967 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:18:17,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:18:17,975 : INFO : EPOCH - 19 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1318476 effective words/s\n",
      "2020-01-08 21:18:18,998 : INFO : EPOCH 20 - PROGRESS: at 5.65% examples, 1262257 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:20,000 : INFO : EPOCH 20 - PROGRESS: at 11.45% examples, 1298282 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:21,006 : INFO : EPOCH 20 - PROGRESS: at 17.29% examples, 1303815 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:22,006 : INFO : EPOCH 20 - PROGRESS: at 23.09% examples, 1314399 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:23,019 : INFO : EPOCH 20 - PROGRESS: at 28.91% examples, 1311759 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:24,028 : INFO : EPOCH 20 - PROGRESS: at 34.71% examples, 1309383 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:25,042 : INFO : EPOCH 20 - PROGRESS: at 40.46% examples, 1307983 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:26,060 : INFO : EPOCH 20 - PROGRESS: at 46.29% examples, 1310952 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:27,074 : INFO : EPOCH 20 - PROGRESS: at 52.05% examples, 1312545 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:28,081 : INFO : EPOCH 20 - PROGRESS: at 57.74% examples, 1313898 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:29,083 : INFO : EPOCH 20 - PROGRESS: at 63.50% examples, 1315022 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:30,090 : INFO : EPOCH 20 - PROGRESS: at 69.16% examples, 1312734 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:31,100 : INFO : EPOCH 20 - PROGRESS: at 75.03% examples, 1312822 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:32,101 : INFO : EPOCH 20 - PROGRESS: at 80.87% examples, 1313710 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:33,124 : INFO : EPOCH 20 - PROGRESS: at 86.64% examples, 1313739 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:34,131 : INFO : EPOCH 20 - PROGRESS: at 92.42% examples, 1313481 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:35,147 : INFO : EPOCH 20 - PROGRESS: at 98.27% examples, 1313706 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:35,393 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:18:35,403 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:18:35,408 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:18:35,415 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:18:35,416 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:18:35,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:18:35,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:18:35,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:18:35,429 : INFO : EPOCH - 20 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1315186 effective words/s\n",
      "2020-01-08 21:18:35,430 : INFO : training on a 465590580 raw words (459020300 effective words) took 351.2s, 1306840 effective words/s\n",
      "2020-01-08 21:18:35,430 : INFO : training model with 8 workers on 265408 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:51.251836\n",
      "Training Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:18:36,474 : INFO : EPOCH 1 - PROGRESS: at 5.65% examples, 1241273 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:37,478 : INFO : EPOCH 1 - PROGRESS: at 11.45% examples, 1286042 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:38,485 : INFO : EPOCH 1 - PROGRESS: at 17.16% examples, 1285380 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:39,487 : INFO : EPOCH 1 - PROGRESS: at 22.74% examples, 1287867 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:40,491 : INFO : EPOCH 1 - PROGRESS: at 28.37% examples, 1285142 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:41,493 : INFO : EPOCH 1 - PROGRESS: at 34.15% examples, 1287206 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:42,494 : INFO : EPOCH 1 - PROGRESS: at 39.88% examples, 1291186 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:43,507 : INFO : EPOCH 1 - PROGRESS: at 45.64% examples, 1293666 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:44,510 : INFO : EPOCH 1 - PROGRESS: at 51.19% examples, 1293495 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:18:45,514 : INFO : EPOCH 1 - PROGRESS: at 56.95% examples, 1298866 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:46,520 : INFO : EPOCH 1 - PROGRESS: at 62.63% examples, 1299039 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:47,527 : INFO : EPOCH 1 - PROGRESS: at 68.34% examples, 1299828 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:48,530 : INFO : EPOCH 1 - PROGRESS: at 74.00% examples, 1297777 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:49,540 : INFO : EPOCH 1 - PROGRESS: at 79.73% examples, 1296432 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:50,545 : INFO : EPOCH 1 - PROGRESS: at 85.37% examples, 1297695 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:51,557 : INFO : EPOCH 1 - PROGRESS: at 91.24% examples, 1299315 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:52,564 : INFO : EPOCH 1 - PROGRESS: at 97.01% examples, 1299836 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:18:53,038 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:18:53,045 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:18:53,047 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:18:53,055 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:18:53,056 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:18:53,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:18:53,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:18:53,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:18:53,072 : INFO : EPOCH - 1 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1301409 effective words/s\n",
      "2020-01-08 21:18:54,095 : INFO : EPOCH 2 - PROGRESS: at 5.65% examples, 1263398 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:55,098 : INFO : EPOCH 2 - PROGRESS: at 11.41% examples, 1293084 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:56,109 : INFO : EPOCH 2 - PROGRESS: at 17.29% examples, 1301765 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:57,113 : INFO : EPOCH 2 - PROGRESS: at 22.86% examples, 1299159 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:58,115 : INFO : EPOCH 2 - PROGRESS: at 28.60% examples, 1298589 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:18:59,116 : INFO : EPOCH 2 - PROGRESS: at 34.24% examples, 1293846 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:00,123 : INFO : EPOCH 2 - PROGRESS: at 39.92% examples, 1294435 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:01,127 : INFO : EPOCH 2 - PROGRESS: at 45.62% examples, 1296851 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:02,138 : INFO : EPOCH 2 - PROGRESS: at 51.40% examples, 1300477 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:03,143 : INFO : EPOCH 2 - PROGRESS: at 57.03% examples, 1302126 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:04,147 : INFO : EPOCH 2 - PROGRESS: at 62.72% examples, 1302266 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:05,147 : INFO : EPOCH 2 - PROGRESS: at 68.47% examples, 1304345 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:06,154 : INFO : EPOCH 2 - PROGRESS: at 74.25% examples, 1303798 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:07,157 : INFO : EPOCH 2 - PROGRESS: at 80.10% examples, 1304705 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:08,158 : INFO : EPOCH 2 - PROGRESS: at 85.76% examples, 1305796 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:09,172 : INFO : EPOCH 2 - PROGRESS: at 91.41% examples, 1303664 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:10,175 : INFO : EPOCH 2 - PROGRESS: at 97.10% examples, 1303104 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:10,639 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:19:10,650 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:19:10,655 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:19:10,658 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:19:10,662 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:19:10,665 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:19:10,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:19:10,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:19:10,677 : INFO : EPOCH - 2 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1303961 effective words/s\n",
      "2020-01-08 21:19:11,700 : INFO : EPOCH 3 - PROGRESS: at 5.65% examples, 1262929 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:12,703 : INFO : EPOCH 3 - PROGRESS: at 11.45% examples, 1298096 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:13,717 : INFO : EPOCH 3 - PROGRESS: at 17.29% examples, 1300299 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:14,718 : INFO : EPOCH 3 - PROGRESS: at 22.95% examples, 1304166 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:15,722 : INFO : EPOCH 3 - PROGRESS: at 28.78% examples, 1305698 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:16,724 : INFO : EPOCH 3 - PROGRESS: at 34.32% examples, 1296208 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:17,729 : INFO : EPOCH 3 - PROGRESS: at 40.06% examples, 1298471 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:18,730 : INFO : EPOCH 3 - PROGRESS: at 45.67% examples, 1298394 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:19,733 : INFO : EPOCH 3 - PROGRESS: at 51.24% examples, 1297619 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:20,742 : INFO : EPOCH 3 - PROGRESS: at 56.82% examples, 1298042 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:21,745 : INFO : EPOCH 3 - PROGRESS: at 62.60% examples, 1300504 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:22,753 : INFO : EPOCH 3 - PROGRESS: at 68.34% examples, 1301804 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:23,753 : INFO : EPOCH 3 - PROGRESS: at 74.21% examples, 1303606 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:24,755 : INFO : EPOCH 3 - PROGRESS: at 79.93% examples, 1302618 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:25,775 : INFO : EPOCH 3 - PROGRESS: at 85.63% examples, 1302808 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:26,775 : INFO : EPOCH 3 - PROGRESS: at 91.45% examples, 1304427 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:27,780 : INFO : EPOCH 3 - PROGRESS: at 97.26% examples, 1305405 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:28,219 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:19:28,226 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:19:28,229 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:19:28,235 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:19:28,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:19:28,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:19:28,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:19:28,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:19:28,254 : INFO : EPOCH - 3 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1306075 effective words/s\n",
      "2020-01-08 21:19:29,282 : INFO : EPOCH 4 - PROGRESS: at 5.65% examples, 1255357 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:30,284 : INFO : EPOCH 4 - PROGRESS: at 11.41% examples, 1289854 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:31,299 : INFO : EPOCH 4 - PROGRESS: at 17.29% examples, 1297951 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:32,303 : INFO : EPOCH 4 - PROGRESS: at 22.86% examples, 1296321 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:33,315 : INFO : EPOCH 4 - PROGRESS: at 28.42% examples, 1286162 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:34,331 : INFO : EPOCH 4 - PROGRESS: at 34.15% examples, 1283371 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:35,337 : INFO : EPOCH 4 - PROGRESS: at 39.88% examples, 1286922 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:36,354 : INFO : EPOCH 4 - PROGRESS: at 45.62% examples, 1289479 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:37,370 : INFO : EPOCH 4 - PROGRESS: at 51.40% examples, 1293204 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:38,372 : INFO : EPOCH 4 - PROGRESS: at 57.03% examples, 1295940 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:39,374 : INFO : EPOCH 4 - PROGRESS: at 62.60% examples, 1294234 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:40,378 : INFO : EPOCH 4 - PROGRESS: at 68.25% examples, 1294963 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:41,380 : INFO : EPOCH 4 - PROGRESS: at 74.00% examples, 1294866 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:42,380 : INFO : EPOCH 4 - PROGRESS: at 79.81% examples, 1295986 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:43,386 : INFO : EPOCH 4 - PROGRESS: at 85.59% examples, 1299142 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:44,394 : INFO : EPOCH 4 - PROGRESS: at 91.32% examples, 1299173 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:45,399 : INFO : EPOCH 4 - PROGRESS: at 97.06% examples, 1299336 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:45,862 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:19:45,871 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:19:45,875 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:19:45,879 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:19:45,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:19:45,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:19:45,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:19:45,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:19:45,898 : INFO : EPOCH - 4 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1301026 effective words/s\n",
      "2020-01-08 21:19:46,902 : INFO : EPOCH 5 - PROGRESS: at 5.53% examples, 1258517 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:19:47,903 : INFO : EPOCH 5 - PROGRESS: at 11.13% examples, 1272895 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:48,905 : INFO : EPOCH 5 - PROGRESS: at 16.93% examples, 1285902 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:49,907 : INFO : EPOCH 5 - PROGRESS: at 22.57% examples, 1292669 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:50,911 : INFO : EPOCH 5 - PROGRESS: at 28.42% examples, 1298597 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:51,921 : INFO : EPOCH 5 - PROGRESS: at 34.24% examples, 1298366 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:52,921 : INFO : EPOCH 5 - PROGRESS: at 40.06% examples, 1303745 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:53,922 : INFO : EPOCH 5 - PROGRESS: at 45.74% examples, 1305438 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:54,942 : INFO : EPOCH 5 - PROGRESS: at 51.52% examples, 1306843 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:55,943 : INFO : EPOCH 5 - PROGRESS: at 57.23% examples, 1310400 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:56,945 : INFO : EPOCH 5 - PROGRESS: at 62.96% examples, 1310805 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:57,950 : INFO : EPOCH 5 - PROGRESS: at 68.74% examples, 1311667 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:19:58,952 : INFO : EPOCH 5 - PROGRESS: at 74.47% examples, 1310341 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:19:59,956 : INFO : EPOCH 5 - PROGRESS: at 80.33% examples, 1311189 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:00,967 : INFO : EPOCH 5 - PROGRESS: at 85.97% examples, 1310464 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:01,975 : INFO : EPOCH 5 - PROGRESS: at 91.74% examples, 1310410 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:02,976 : INFO : EPOCH 5 - PROGRESS: at 97.51% examples, 1310717 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:03,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:20:03,388 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:20:03,393 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:20:03,398 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:20:03,402 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:20:03,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:20:03,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:20:03,415 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:20:03,416 : INFO : EPOCH - 5 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1310465 effective words/s\n",
      "2020-01-08 21:20:04,443 : INFO : EPOCH 6 - PROGRESS: at 5.65% examples, 1257709 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:05,448 : INFO : EPOCH 6 - PROGRESS: at 11.45% examples, 1294093 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:06,453 : INFO : EPOCH 6 - PROGRESS: at 17.29% examples, 1301269 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:07,455 : INFO : EPOCH 6 - PROGRESS: at 23.04% examples, 1309477 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:08,470 : INFO : EPOCH 6 - PROGRESS: at 28.91% examples, 1308993 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:09,484 : INFO : EPOCH 6 - PROGRESS: at 34.72% examples, 1306280 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:10,484 : INFO : EPOCH 6 - PROGRESS: at 40.46% examples, 1307814 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:11,485 : INFO : EPOCH 6 - PROGRESS: at 46.24% examples, 1312287 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:12,487 : INFO : EPOCH 6 - PROGRESS: at 51.89% examples, 1312347 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:13,496 : INFO : EPOCH 6 - PROGRESS: at 57.62% examples, 1314286 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:14,506 : INFO : EPOCH 6 - PROGRESS: at 63.27% examples, 1311887 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:15,507 : INFO : EPOCH 6 - PROGRESS: at 69.03% examples, 1312987 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:16,513 : INFO : EPOCH 6 - PROGRESS: at 74.87% examples, 1312634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:17,517 : INFO : EPOCH 6 - PROGRESS: at 80.70% examples, 1313299 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:18,518 : INFO : EPOCH 6 - PROGRESS: at 86.33% examples, 1313366 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:19,522 : INFO : EPOCH 6 - PROGRESS: at 92.10% examples, 1313377 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:20,523 : INFO : EPOCH 6 - PROGRESS: at 97.94% examples, 1314162 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:20,832 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:20:20,843 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:20:20,846 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:20:20,850 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:20:20,854 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:20:20,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:20:20,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:20:20,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:20:20,871 : INFO : EPOCH - 6 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1315115 effective words/s\n",
      "2020-01-08 21:20:21,898 : INFO : EPOCH 7 - PROGRESS: at 5.65% examples, 1258794 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:22,898 : INFO : EPOCH 7 - PROGRESS: at 11.59% examples, 1311755 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:23,899 : INFO : EPOCH 7 - PROGRESS: at 17.33% examples, 1308378 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:24,902 : INFO : EPOCH 7 - PROGRESS: at 23.00% examples, 1309698 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:25,914 : INFO : EPOCH 7 - PROGRESS: at 28.91% examples, 1312069 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:26,916 : INFO : EPOCH 7 - PROGRESS: at 34.70% examples, 1311314 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:27,917 : INFO : EPOCH 7 - PROGRESS: at 40.46% examples, 1311940 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:28,921 : INFO : EPOCH 7 - PROGRESS: at 46.12% examples, 1311995 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:29,932 : INFO : EPOCH 7 - PROGRESS: at 51.85% examples, 1312929 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:30,941 : INFO : EPOCH 7 - PROGRESS: at 57.40% examples, 1310895 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:31,955 : INFO : EPOCH 7 - PROGRESS: at 63.27% examples, 1312623 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:32,961 : INFO : EPOCH 7 - PROGRESS: at 69.03% examples, 1313099 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:33,963 : INFO : EPOCH 7 - PROGRESS: at 74.87% examples, 1313192 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:34,978 : INFO : EPOCH 7 - PROGRESS: at 80.74% examples, 1313492 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:36,002 : INFO : EPOCH 7 - PROGRESS: at 86.64% examples, 1315405 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:37,002 : INFO : EPOCH 7 - PROGRESS: at 92.52% examples, 1317391 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:38,004 : INFO : EPOCH 7 - PROGRESS: at 98.27% examples, 1316743 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:38,262 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:20:38,266 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:20:38,273 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:20:38,280 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:20:38,281 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:20:38,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:20:38,291 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:20:38,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:20:38,298 : INFO : EPOCH - 7 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1317299 effective words/s\n",
      "2020-01-08 21:20:39,302 : INFO : EPOCH 8 - PROGRESS: at 5.49% examples, 1249265 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:40,305 : INFO : EPOCH 8 - PROGRESS: at 11.21% examples, 1280986 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:41,307 : INFO : EPOCH 8 - PROGRESS: at 17.01% examples, 1291020 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:42,310 : INFO : EPOCH 8 - PROGRESS: at 22.78% examples, 1303854 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:43,314 : INFO : EPOCH 8 - PROGRESS: at 28.56% examples, 1303408 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:44,316 : INFO : EPOCH 8 - PROGRESS: at 34.24% examples, 1299297 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:45,320 : INFO : EPOCH 8 - PROGRESS: at 40.06% examples, 1303792 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:46,327 : INFO : EPOCH 8 - PROGRESS: at 45.77% examples, 1305644 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:47,335 : INFO : EPOCH 8 - PROGRESS: at 51.52% examples, 1307819 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:20:48,337 : INFO : EPOCH 8 - PROGRESS: at 57.23% examples, 1311040 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:49,346 : INFO : EPOCH 8 - PROGRESS: at 62.96% examples, 1310632 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:50,350 : INFO : EPOCH 8 - PROGRESS: at 68.75% examples, 1311566 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:51,363 : INFO : EPOCH 8 - PROGRESS: at 74.60% examples, 1311432 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:52,369 : INFO : EPOCH 8 - PROGRESS: at 80.41% examples, 1311374 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:53,369 : INFO : EPOCH 8 - PROGRESS: at 86.25% examples, 1314713 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:54,386 : INFO : EPOCH 8 - PROGRESS: at 91.99% examples, 1313058 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:55,390 : INFO : EPOCH 8 - PROGRESS: at 97.81% examples, 1313652 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:55,726 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:20:55,735 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:20:55,741 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:20:55,746 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:20:55,748 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:20:55,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:20:55,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:20:55,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:20:55,763 : INFO : EPOCH - 8 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1314379 effective words/s\n",
      "2020-01-08 21:20:56,783 : INFO : EPOCH 9 - PROGRESS: at 5.65% examples, 1266439 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:57,786 : INFO : EPOCH 9 - PROGRESS: at 11.50% examples, 1305065 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:58,788 : INFO : EPOCH 9 - PROGRESS: at 17.25% examples, 1303550 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:20:59,793 : INFO : EPOCH 9 - PROGRESS: at 22.99% examples, 1310057 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:00,809 : INFO : EPOCH 9 - PROGRESS: at 28.91% examples, 1311195 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:01,812 : INFO : EPOCH 9 - PROGRESS: at 34.70% examples, 1310344 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:02,814 : INFO : EPOCH 9 - PROGRESS: at 40.46% examples, 1310965 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:03,823 : INFO : EPOCH 9 - PROGRESS: at 46.12% examples, 1310210 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:04,830 : INFO : EPOCH 9 - PROGRESS: at 51.85% examples, 1311975 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:05,834 : INFO : EPOCH 9 - PROGRESS: at 57.53% examples, 1313674 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:06,834 : INFO : EPOCH 9 - PROGRESS: at 63.34% examples, 1315876 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:07,843 : INFO : EPOCH 9 - PROGRESS: at 69.07% examples, 1314980 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:08,847 : INFO : EPOCH 9 - PROGRESS: at 74.83% examples, 1313244 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:09,847 : INFO : EPOCH 9 - PROGRESS: at 80.54% examples, 1312154 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:10,849 : INFO : EPOCH 9 - PROGRESS: at 86.20% examples, 1312827 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:11,862 : INFO : EPOCH 9 - PROGRESS: at 91.99% examples, 1312175 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:12,862 : INFO : EPOCH 9 - PROGRESS: at 97.81% examples, 1313067 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:13,196 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:21:13,206 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:21:13,209 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:21:13,215 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:21:13,218 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:21:13,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:21:13,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:21:13,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:21:13,233 : INFO : EPOCH - 9 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1314029 effective words/s\n",
      "2020-01-08 21:21:14,246 : INFO : EPOCH 10 - PROGRESS: at 5.65% examples, 1275535 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:15,253 : INFO : EPOCH 10 - PROGRESS: at 11.54% examples, 1311445 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:16,260 : INFO : EPOCH 10 - PROGRESS: at 17.21% examples, 1299187 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:17,262 : INFO : EPOCH 10 - PROGRESS: at 22.45% examples, 1278689 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:18,264 : INFO : EPOCH 10 - PROGRESS: at 28.06% examples, 1278496 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:19,273 : INFO : EPOCH 10 - PROGRESS: at 33.89% examples, 1281765 words/s, in_qsize 16, out_qsize 1\n",
      "2020-01-08 21:21:20,276 : INFO : EPOCH 10 - PROGRESS: at 39.73% examples, 1288889 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:21,277 : INFO : EPOCH 10 - PROGRESS: at 45.46% examples, 1293753 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:22,296 : INFO : EPOCH 10 - PROGRESS: at 51.20% examples, 1295456 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:21:23,297 : INFO : EPOCH 10 - PROGRESS: at 56.94% examples, 1301053 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:24,302 : INFO : EPOCH 10 - PROGRESS: at 62.67% examples, 1302057 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:25,304 : INFO : EPOCH 10 - PROGRESS: at 68.34% examples, 1302366 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:26,320 : INFO : EPOCH 10 - PROGRESS: at 74.25% examples, 1303237 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:27,328 : INFO : EPOCH 10 - PROGRESS: at 80.13% examples, 1304337 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:28,329 : INFO : EPOCH 10 - PROGRESS: at 85.76% examples, 1304869 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:29,331 : INFO : EPOCH 10 - PROGRESS: at 91.57% examples, 1306218 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:30,335 : INFO : EPOCH 10 - PROGRESS: at 97.31% examples, 1306056 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:30,754 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:21:30,769 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:21:30,770 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:21:30,775 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:21:30,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:21:30,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:21:30,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:21:30,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:21:30,791 : INFO : EPOCH - 10 : training on 23279529 raw words (22951015 effective words) took 17.6s, 1307460 effective words/s\n",
      "2020-01-08 21:21:31,806 : INFO : EPOCH 11 - PROGRESS: at 5.65% examples, 1272863 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:32,807 : INFO : EPOCH 11 - PROGRESS: at 11.50% examples, 1309472 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:33,812 : INFO : EPOCH 11 - PROGRESS: at 17.38% examples, 1314614 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:34,829 : INFO : EPOCH 11 - PROGRESS: at 23.16% examples, 1317021 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:35,837 : INFO : EPOCH 11 - PROGRESS: at 29.04% examples, 1317050 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:36,838 : INFO : EPOCH 11 - PROGRESS: at 34.88% examples, 1317108 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:37,839 : INFO : EPOCH 11 - PROGRESS: at 40.63% examples, 1316974 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:38,845 : INFO : EPOCH 11 - PROGRESS: at 46.38% examples, 1318421 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:39,847 : INFO : EPOCH 11 - PROGRESS: at 52.13% examples, 1320967 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:40,853 : INFO : EPOCH 11 - PROGRESS: at 57.90% examples, 1323554 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:41,860 : INFO : EPOCH 11 - PROGRESS: at 63.39% examples, 1316986 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:42,868 : INFO : EPOCH 11 - PROGRESS: at 68.94% examples, 1312846 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:43,870 : INFO : EPOCH 11 - PROGRESS: at 74.60% examples, 1310002 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:44,877 : INFO : EPOCH 11 - PROGRESS: at 80.42% examples, 1309969 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:45,909 : INFO : EPOCH 11 - PROGRESS: at 86.29% examples, 1311322 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:46,910 : INFO : EPOCH 11 - PROGRESS: at 92.10% examples, 1312336 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:47,917 : INFO : EPOCH 11 - PROGRESS: at 97.98% examples, 1313280 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:48,214 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:21:48,223 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:21:48,229 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:21:48,233 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:21:48,235 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:21:48,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:21:48,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:21:48,252 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:21:48,252 : INFO : EPOCH - 11 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1314660 effective words/s\n",
      "2020-01-08 21:21:49,278 : INFO : EPOCH 12 - PROGRESS: at 5.65% examples, 1259681 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:50,279 : INFO : EPOCH 12 - PROGRESS: at 11.50% examples, 1302398 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:51,279 : INFO : EPOCH 12 - PROGRESS: at 17.29% examples, 1305785 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:52,281 : INFO : EPOCH 12 - PROGRESS: at 23.12% examples, 1317671 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:21:53,287 : INFO : EPOCH 12 - PROGRESS: at 28.91% examples, 1314108 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:54,293 : INFO : EPOCH 12 - PROGRESS: at 34.70% examples, 1312197 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:55,294 : INFO : EPOCH 12 - PROGRESS: at 40.46% examples, 1312658 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:56,305 : INFO : EPOCH 12 - PROGRESS: at 46.29% examples, 1316310 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:57,310 : INFO : EPOCH 12 - PROGRESS: at 52.01% examples, 1317434 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:58,318 : INFO : EPOCH 12 - PROGRESS: at 57.62% examples, 1316212 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:21:59,330 : INFO : EPOCH 12 - PROGRESS: at 63.38% examples, 1315986 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:00,334 : INFO : EPOCH 12 - PROGRESS: at 69.16% examples, 1316390 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:01,339 : INFO : EPOCH 12 - PROGRESS: at 74.99% examples, 1315982 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:02,339 : INFO : EPOCH 12 - PROGRESS: at 80.78% examples, 1316038 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:03,343 : INFO : EPOCH 12 - PROGRESS: at 86.56% examples, 1317575 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:22:04,351 : INFO : EPOCH 12 - PROGRESS: at 92.29% examples, 1316395 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:05,354 : INFO : EPOCH 12 - PROGRESS: at 97.98% examples, 1315152 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:05,670 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:22:05,680 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:22:05,689 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:22:05,691 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:22:05,693 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:22:05,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:22:05,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:22:05,707 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:22:05,707 : INFO : EPOCH - 12 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1315157 effective words/s\n",
      "2020-01-08 21:22:06,740 : INFO : EPOCH 13 - PROGRESS: at 5.65% examples, 1250837 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:07,741 : INFO : EPOCH 13 - PROGRESS: at 11.50% examples, 1297731 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:08,745 : INFO : EPOCH 13 - PROGRESS: at 17.33% examples, 1304444 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:09,770 : INFO : EPOCH 13 - PROGRESS: at 23.16% examples, 1309264 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:10,773 : INFO : EPOCH 13 - PROGRESS: at 29.20% examples, 1319668 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:11,776 : INFO : EPOCH 13 - PROGRESS: at 35.11% examples, 1320525 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:12,778 : INFO : EPOCH 13 - PROGRESS: at 40.93% examples, 1322450 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:13,788 : INFO : EPOCH 13 - PROGRESS: at 46.62% examples, 1321260 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:14,791 : INFO : EPOCH 13 - PROGRESS: at 52.26% examples, 1320215 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:15,794 : INFO : EPOCH 13 - PROGRESS: at 57.79% examples, 1317394 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:16,802 : INFO : EPOCH 13 - PROGRESS: at 63.58% examples, 1318391 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:17,810 : INFO : EPOCH 13 - PROGRESS: at 69.37% examples, 1318228 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:18,820 : INFO : EPOCH 13 - PROGRESS: at 75.30% examples, 1318545 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:19,821 : INFO : EPOCH 13 - PROGRESS: at 81.15% examples, 1319664 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:20,823 : INFO : EPOCH 13 - PROGRESS: at 86.92% examples, 1320580 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:22:21,827 : INFO : EPOCH 13 - PROGRESS: at 92.70% examples, 1320671 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:22,835 : INFO : EPOCH 13 - PROGRESS: at 98.50% examples, 1319944 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:22:23,044 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:22:23,055 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:22:23,062 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:22:23,065 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:22:23,067 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:22:23,071 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:22:23,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:22:23,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:22:23,082 : INFO : EPOCH - 13 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1321243 effective words/s\n",
      "2020-01-08 21:22:24,103 : INFO : EPOCH 14 - PROGRESS: at 5.65% examples, 1265292 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:25,107 : INFO : EPOCH 14 - PROGRESS: at 11.45% examples, 1298749 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:26,108 : INFO : EPOCH 14 - PROGRESS: at 17.33% examples, 1309459 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:27,132 : INFO : EPOCH 14 - PROGRESS: at 23.16% examples, 1313135 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:28,134 : INFO : EPOCH 14 - PROGRESS: at 28.95% examples, 1311667 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:29,141 : INFO : EPOCH 14 - PROGRESS: at 34.84% examples, 1312963 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:30,145 : INFO : EPOCH 14 - PROGRESS: at 40.63% examples, 1314247 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:31,148 : INFO : EPOCH 14 - PROGRESS: at 46.38% examples, 1316480 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:32,154 : INFO : EPOCH 14 - PROGRESS: at 52.18% examples, 1319805 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:33,158 : INFO : EPOCH 14 - PROGRESS: at 57.90% examples, 1321720 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:34,162 : INFO : EPOCH 14 - PROGRESS: at 63.62% examples, 1321000 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:35,162 : INFO : EPOCH 14 - PROGRESS: at 69.37% examples, 1320623 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:36,172 : INFO : EPOCH 14 - PROGRESS: at 75.34% examples, 1321570 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:37,179 : INFO : EPOCH 14 - PROGRESS: at 81.24% examples, 1322590 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:38,198 : INFO : EPOCH 14 - PROGRESS: at 87.01% examples, 1321858 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:39,200 : INFO : EPOCH 14 - PROGRESS: at 92.86% examples, 1323239 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:40,200 : INFO : EPOCH 14 - PROGRESS: at 98.63% examples, 1322367 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:40,391 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:22:40,405 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:22:40,408 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:22:40,415 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:22:40,418 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:22:40,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:22:40,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:22:40,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:22:40,428 : INFO : EPOCH - 14 : training on 23279529 raw words (22951015 effective words) took 17.3s, 1323450 effective words/s\n",
      "2020-01-08 21:22:41,446 : INFO : EPOCH 15 - PROGRESS: at 5.65% examples, 1269977 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:42,446 : INFO : EPOCH 15 - PROGRESS: at 11.59% examples, 1317611 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:43,455 : INFO : EPOCH 15 - PROGRESS: at 17.42% examples, 1315368 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:44,464 : INFO : EPOCH 15 - PROGRESS: at 22.78% examples, 1296277 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:45,468 : INFO : EPOCH 15 - PROGRESS: at 28.37% examples, 1289783 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:46,476 : INFO : EPOCH 15 - PROGRESS: at 34.24% examples, 1293038 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:47,483 : INFO : EPOCH 15 - PROGRESS: at 40.06% examples, 1297899 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:48,487 : INFO : EPOCH 15 - PROGRESS: at 45.74% examples, 1299793 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:49,502 : INFO : EPOCH 15 - PROGRESS: at 51.52% examples, 1302558 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:50,517 : INFO : EPOCH 15 - PROGRESS: at 57.40% examples, 1308540 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:51,530 : INFO : EPOCH 15 - PROGRESS: at 63.26% examples, 1310495 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:52,532 : INFO : EPOCH 15 - PROGRESS: at 69.07% examples, 1312489 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:53,535 : INFO : EPOCH 15 - PROGRESS: at 74.95% examples, 1313176 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:22:54,551 : INFO : EPOCH 15 - PROGRESS: at 80.67% examples, 1310671 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:22:55,559 : INFO : EPOCH 15 - PROGRESS: at 86.30% examples, 1310253 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:56,560 : INFO : EPOCH 15 - PROGRESS: at 92.11% examples, 1311245 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:57,567 : INFO : EPOCH 15 - PROGRESS: at 97.98% examples, 1312322 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:57,865 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:22:57,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:22:57,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:22:57,891 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:22:57,894 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:22:57,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:22:57,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:22:57,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:22:57,907 : INFO : EPOCH - 15 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1313376 effective words/s\n",
      "2020-01-08 21:22:58,914 : INFO : EPOCH 16 - PROGRESS: at 5.49% examples, 1248074 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:22:59,932 : INFO : EPOCH 16 - PROGRESS: at 11.33% examples, 1285729 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:00,933 : INFO : EPOCH 16 - PROGRESS: at 17.16% examples, 1297715 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:01,941 : INFO : EPOCH 16 - PROGRESS: at 22.87% examples, 1302187 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:02,944 : INFO : EPOCH 16 - PROGRESS: at 28.74% examples, 1306451 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:03,945 : INFO : EPOCH 16 - PROGRESS: at 34.54% examples, 1306714 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:04,956 : INFO : EPOCH 16 - PROGRESS: at 40.30% examples, 1306215 words/s, in_qsize 14, out_qsize 1\n",
      "2020-01-08 21:23:05,958 : INFO : EPOCH 16 - PROGRESS: at 46.04% examples, 1309775 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:06,959 : INFO : EPOCH 16 - PROGRESS: at 51.82% examples, 1313355 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:07,961 : INFO : EPOCH 16 - PROGRESS: at 57.45% examples, 1314219 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:08,980 : INFO : EPOCH 16 - PROGRESS: at 63.27% examples, 1314151 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:09,985 : INFO : EPOCH 16 - PROGRESS: at 68.94% examples, 1313092 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:10,991 : INFO : EPOCH 16 - PROGRESS: at 74.64% examples, 1310455 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:11,997 : INFO : EPOCH 16 - PROGRESS: at 80.54% examples, 1311864 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:13,018 : INFO : EPOCH 16 - PROGRESS: at 86.29% examples, 1312151 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:14,026 : INFO : EPOCH 16 - PROGRESS: at 92.06% examples, 1311893 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:15,027 : INFO : EPOCH 16 - PROGRESS: at 97.94% examples, 1313327 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:15,333 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:23:15,343 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:23:15,348 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:23:15,353 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:23:15,354 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:23:15,358 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:23:15,360 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:23:15,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:23:15,367 : INFO : EPOCH - 16 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1314926 effective words/s\n",
      "2020-01-08 21:23:16,373 : INFO : EPOCH 17 - PROGRESS: at 5.57% examples, 1265317 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:17,377 : INFO : EPOCH 17 - PROGRESS: at 11.02% examples, 1255067 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:18,378 : INFO : EPOCH 17 - PROGRESS: at 16.64% examples, 1261927 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:19,379 : INFO : EPOCH 17 - PROGRESS: at 22.23% examples, 1272448 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:20,382 : INFO : EPOCH 17 - PROGRESS: at 28.05% examples, 1282432 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:21,388 : INFO : EPOCH 17 - PROGRESS: at 33.89% examples, 1285903 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:22,395 : INFO : EPOCH 17 - PROGRESS: at 39.77% examples, 1293135 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:23,397 : INFO : EPOCH 17 - PROGRESS: at 45.51% examples, 1297206 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:24,407 : INFO : EPOCH 17 - PROGRESS: at 51.20% examples, 1298823 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:25,409 : INFO : EPOCH 17 - PROGRESS: at 56.91% examples, 1302959 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:26,417 : INFO : EPOCH 17 - PROGRESS: at 62.72% examples, 1305145 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:27,417 : INFO : EPOCH 17 - PROGRESS: at 68.52% examples, 1307788 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:28,427 : INFO : EPOCH 17 - PROGRESS: at 74.25% examples, 1306007 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:29,431 : INFO : EPOCH 17 - PROGRESS: at 80.13% examples, 1307221 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:30,465 : INFO : EPOCH 17 - PROGRESS: at 85.96% examples, 1307930 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:31,465 : INFO : EPOCH 17 - PROGRESS: at 91.91% examples, 1311064 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:32,470 : INFO : EPOCH 17 - PROGRESS: at 97.64% examples, 1310561 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:32,827 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:23:32,834 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:23:32,837 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:23:32,845 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:23:32,847 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:23:32,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:23:32,854 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:23:32,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:23:32,864 : INFO : EPOCH - 17 : training on 23279529 raw words (22951015 effective words) took 17.5s, 1311990 effective words/s\n",
      "2020-01-08 21:23:33,882 : INFO : EPOCH 18 - PROGRESS: at 5.65% examples, 1268774 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:34,885 : INFO : EPOCH 18 - PROGRESS: at 11.45% examples, 1300815 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:35,894 : INFO : EPOCH 18 - PROGRESS: at 17.38% examples, 1310551 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:36,911 : INFO : EPOCH 18 - PROGRESS: at 23.16% examples, 1314229 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:37,915 : INFO : EPOCH 18 - PROGRESS: at 29.04% examples, 1315851 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:38,915 : INFO : EPOCH 18 - PROGRESS: at 34.88% examples, 1316369 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:39,915 : INFO : EPOCH 18 - PROGRESS: at 40.63% examples, 1316424 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:40,916 : INFO : EPOCH 18 - PROGRESS: at 46.33% examples, 1317642 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:41,916 : INFO : EPOCH 18 - PROGRESS: at 52.09% examples, 1320496 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:42,920 : INFO : EPOCH 18 - PROGRESS: at 57.79% examples, 1321341 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:43,942 : INFO : EPOCH 18 - PROGRESS: at 63.58% examples, 1320348 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 21:23:44,954 : INFO : EPOCH 18 - PROGRESS: at 69.39% examples, 1319563 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:45,956 : INFO : EPOCH 18 - PROGRESS: at 75.25% examples, 1319866 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:46,962 : INFO : EPOCH 18 - PROGRESS: at 81.05% examples, 1319083 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:47,965 : INFO : EPOCH 18 - PROGRESS: at 86.82% examples, 1320560 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:48,966 : INFO : EPOCH 18 - PROGRESS: at 92.62% examples, 1320920 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:49,979 : INFO : EPOCH 18 - PROGRESS: at 98.31% examples, 1318588 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:50,216 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:23:50,220 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:23:50,225 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:23:50,228 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:23:50,232 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:23:50,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:23:50,240 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:23:50,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:23:50,250 : INFO : EPOCH - 18 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1320378 effective words/s\n",
      "2020-01-08 21:23:51,273 : INFO : EPOCH 19 - PROGRESS: at 5.65% examples, 1267094 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:52,275 : INFO : EPOCH 19 - PROGRESS: at 11.54% examples, 1310703 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:53,281 : INFO : EPOCH 19 - PROGRESS: at 17.38% examples, 1312051 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:54,292 : INFO : EPOCH 19 - PROGRESS: at 23.16% examples, 1316907 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:23:55,296 : INFO : EPOCH 19 - PROGRESS: at 28.95% examples, 1314214 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:56,297 : INFO : EPOCH 19 - PROGRESS: at 34.86% examples, 1316449 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:57,306 : INFO : EPOCH 19 - PROGRESS: at 40.63% examples, 1316198 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:58,310 : INFO : EPOCH 19 - PROGRESS: at 46.29% examples, 1315660 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:23:59,317 : INFO : EPOCH 19 - PROGRESS: at 52.05% examples, 1317717 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:00,327 : INFO : EPOCH 19 - PROGRESS: at 57.77% examples, 1319093 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:01,331 : INFO : EPOCH 19 - PROGRESS: at 63.58% examples, 1320431 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:24:02,339 : INFO : EPOCH 19 - PROGRESS: at 69.39% examples, 1320087 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:03,339 : INFO : EPOCH 19 - PROGRESS: at 75.25% examples, 1320572 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:04,354 : INFO : EPOCH 19 - PROGRESS: at 81.05% examples, 1318908 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:05,360 : INFO : EPOCH 19 - PROGRESS: at 86.87% examples, 1320706 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:06,362 : INFO : EPOCH 19 - PROGRESS: at 92.66% examples, 1320960 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:07,366 : INFO : EPOCH 19 - PROGRESS: at 98.50% examples, 1321114 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:07,582 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:24:07,594 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:24:07,596 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:24:07,599 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:24:07,604 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:24:07,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:24:07,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:24:07,616 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:24:07,617 : INFO : EPOCH - 19 : training on 23279529 raw words (22951015 effective words) took 17.4s, 1322091 effective words/s\n",
      "2020-01-08 21:24:08,633 : INFO : EPOCH 20 - PROGRESS: at 5.65% examples, 1271210 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:09,636 : INFO : EPOCH 20 - PROGRESS: at 11.59% examples, 1316763 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:10,651 : INFO : EPOCH 20 - PROGRESS: at 17.46% examples, 1315521 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:11,656 : INFO : EPOCH 20 - PROGRESS: at 23.24% examples, 1321606 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:12,673 : INFO : EPOCH 20 - PROGRESS: at 29.24% examples, 1323929 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:13,676 : INFO : EPOCH 20 - PROGRESS: at 35.11% examples, 1322468 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:14,681 : INFO : EPOCH 20 - PROGRESS: at 40.81% examples, 1319634 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:15,693 : INFO : EPOCH 20 - PROGRESS: at 46.62% examples, 1321991 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:24:16,700 : INFO : EPOCH 20 - PROGRESS: at 52.39% examples, 1323453 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:17,703 : INFO : EPOCH 20 - PROGRESS: at 58.15% examples, 1326140 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:18,703 : INFO : EPOCH 20 - PROGRESS: at 63.91% examples, 1326333 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:19,707 : INFO : EPOCH 20 - PROGRESS: at 69.72% examples, 1325872 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:24:20,716 : INFO : EPOCH 20 - PROGRESS: at 75.65% examples, 1325829 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:21,722 : INFO : EPOCH 20 - PROGRESS: at 81.57% examples, 1327326 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:22,736 : INFO : EPOCH 20 - PROGRESS: at 87.36% examples, 1326715 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:23,742 : INFO : EPOCH 20 - PROGRESS: at 93.23% examples, 1327479 words/s, in_qsize 16, out_qsize 0\n",
      "2020-01-08 21:24:24,756 : INFO : EPOCH 20 - PROGRESS: at 99.01% examples, 1325816 words/s, in_qsize 15, out_qsize 0\n",
      "2020-01-08 21:24:24,883 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-01-08 21:24:24,888 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-01-08 21:24:24,893 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-01-08 21:24:24,900 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-01-08 21:24:24,903 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-08 21:24:24,905 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-08 21:24:24,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-08 21:24:24,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-08 21:24:24,917 : INFO : EPOCH - 20 : training on 23279529 raw words (22951015 effective words) took 17.3s, 1326894 effective words/s\n",
      "2020-01-08 21:24:24,918 : INFO : training on a 465590580 raw words (459020300 effective words) took 349.5s, 1313436 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:49.487909\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from random import shuffle\n",
    "shuffled_alldocs = alldocs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "\n",
    "for model in simple_models:\n",
    "    start=datetime.now()\n",
    "    print(\"Training %s\\n\" % model)\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "    print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-30 21:04:35,899 : INFO : storing 265408x100 projection weights into models/3modeldbowwv\n",
      "2019-12-30 21:04:58,972 : INFO : storing 265408x100 projection weights into models/3modeldm1wv\n",
      "2019-12-30 21:05:15,508 : INFO : storing 265408x100 projection weights into models/3modeldm2wv\n"
     ]
    }
   ],
   "source": [
    "# simple_models[0].save_word2vec_format(\"models/modeldbowiter10\",doctag_vec=True)\n",
    "# simple_models[1].save_word2vec_format(\"models/modeldmw2\",doctag_vec=True)\n",
    "# simple_models[2].save_word2vec_format(\"models/modeldmmc5w5\",doctag_vec=True)\n",
    "# simple_models[3].save_word2vec_format(\"models/modeldmc5w2\",doctag_vec=True)\n",
    "simple_models[0].save_word2vec_format(\"models/3modeldbowwv\",doctag_vec=False)\n",
    "simple_models[1].save_word2vec_format(\"models/3modeldm1wv\",doctag_vec=False)\n",
    "simple_models[2].save_word2vec_format(\"models/3modeldm2wv\",doctag_vec=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier and updating hypeparameters using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docvecs_from_testdata(model, test_docs):\n",
    "    inferred_docvecs = []\n",
    "    test_targets = []\n",
    "    for doc in test_docs:\n",
    "        test_targets.append(doc.sentiment)\n",
    "        inferred_docvecs.append(model.infer_vector(doc.words))\n",
    "    return inferred_docvecs,test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t8)\n",
      "\n",
      " Doc2Vec(dbow,d100,n5,mc2,t8) 0.070000 14 0.930000 186\n",
      "\n",
      "0:00:04.009076\n",
      "\n",
      "Evaluating Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8)\n",
      "\n",
      " Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8) 0.125000 25 0.875000 175\n",
      "\n",
      "0:00:05.473336\n",
      "\n",
      "Evaluating Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8)\n",
      "\n",
      " Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8) 0.125000 25 0.875000 175\n",
      "\n",
      "0:00:04.261728\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8)\n",
      "\n",
      " Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8) 0.090000 18 0.910000 182\n",
      "\n",
      "0:00:08.376570\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8)\n",
      "\n",
      " Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8) 0.075000 15 0.925000 185\n",
      "\n",
      "0:00:07.958765\n"
     ]
    }
   ],
   "source": [
    "# #test all the models \n",
    "modelPredictions = collections.namedtuple('modelPredictions', 'index model predictions sentiment')\n",
    "allpreds = []\n",
    "idx = 1\n",
    "for model in simple_models:\n",
    "    start=datetime.now()\n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "#     err_rate, err_count, cor_rate, cor_counts, test_count, predictor, test_pred, test_senti = error_rate_for_model(model, train_docs, test_docs)\n",
    "    '''with cross validation and blind test set'''\n",
    "    test_set, test_targets = get_docvecs_from_testdata(model, cv_test_docs)\n",
    "    err_rate, err_count, cor_rate, cor_counts, test_count, predictor, test_pred, test_senti = result_rates_for_model(model, cv_train_docs, test_set, test_targets)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    allpreds.append(modelPredictions(idx, str(model),test_pred,test_senti))\n",
    "    idx+=1\n",
    "    print(\"\\n %s %f %d %f %d\\n\" % (model, err_rate, err_count, cor_rate, cor_counts))\n",
    "    print(datetime.now()-start)\n",
    "\n",
    "\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    start=datetime.now()\n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    test_set, test_targets = get_docvecs_from_testdata(model, cv_test_docs)\n",
    "    err_rate, err_count, cor_rate, cor_counts, test_count, predictor, test_pred, test_senti = result_rates_for_model(model, cv_train_docs, test_set, test_targets)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    allpreds.append(modelPredictions(idx, str(model),test_pred,test_senti))\n",
    "    idx+=1\n",
    "    print(\"\\n %s %f %d %f %d\\n\" % (model, err_rate, err_count, cor_rate, cor_counts))\n",
    "    print(datetime.now()-start)\n",
    "#test one\n",
    "# for model in simple_models:\n",
    "#     print(\"\\nEvaluating %s\" % model)\n",
    "# #     err_rate, err_count, cor_rate, cor_counts, test_count, predictor, test_pred, test_senti = error_rate_for_model(model, train_docs, test_docs)\n",
    "#     '''with cross validation and blind test set'''\n",
    "#     test_set, test_targets = get_docvecs_from_testdata(model, cv_test_docs)\n",
    "#     err_rate, err_count, cor_rate, cor_counts, test_count, predictor, test_pred, test_senti = result_rates_for_model(model, cv_train_docs, test_set, test_targets)\n",
    "#     error_rates[str(model)] = err_rate\n",
    "#     allpreds.append(modelPredictions(str(model),test_pred,test_senti))\n",
    "#     print(\"\\n %s %f %d %f %d\\n\" % (model, err_rate, err_count, cor_rate, cor_counts))\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining Results\n",
    "-----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx =0 \n",
    "# print(allpreds[idx].predictions)\n",
    "import pickle \n",
    "filehandler = open(\"models/allpredictions_ep10.pickle\", 'wb') \n",
    "pickle.dump(allpreds, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_perm_test_p(a, b, R):\n",
    "    '''\n",
    "    Monte Carlo permutation test\n",
    "    '''\n",
    "    assert len(a)==len(b)\n",
    "    n, k = len(a), 0\n",
    "    diff = np.abs(np.mean(a) - np.mean(b))\n",
    "    coin_bag = np.concatenate([a, b])\n",
    "    for j in range(R):\n",
    "        np.random.shuffle(coin_bag)\n",
    "        k += diff > np.abs(np.mean(coin_bag[:n]) - np.mean(coin_bag[n:]))\n",
    "    k = R-k\n",
    "    print(k)\n",
    "    return (k+1) / (R+1)\n",
    "\n",
    "def xor_op(ls1,ls2):\n",
    "    temp = []\n",
    "    for n,m in zip(ls1, ls2):\n",
    "        temp.append(int(n)^int(m))\n",
    "    return temp\n",
    "\n",
    "def monte_carlo_perm_test(allpreds, R):\n",
    "    p_value = defaultdict(lambda:0.0)  #p_value[str(model)]=monte_carlo_perm_test(x,y,5000)\n",
    "\n",
    "    for pair in list(combinations(np.arange(5),2)):\n",
    "        idx1, idx2 = pair[0], pair[1]\n",
    "        name = str(allpreds[idx1].index)+\"/\"+str(allpreds[idx2].index)\n",
    "#         print(allpreds[idx1].predictions)\n",
    "        a = xor_op(allpreds[idx1].predictions,allpreds[idx1].sentiment)\n",
    "        b = xor_op(allpreds[idx2].predictions,allpreds[idx2].sentiment)\n",
    "        p_value[name]=get_perm_test_p(a,b,R)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "150\n",
      "1068\n",
      "2935\n",
      "4443\n",
      "1465\n",
      "419\n",
      "2187\n",
      "756\n",
      "3046\n"
     ]
    }
   ],
   "source": [
    "p_value = monte_carlo_perm_test(allpreds, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2   0.012198\n",
      "1/3   0.030194\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1/4   0.213757\n",
      "1/5   0.587083\n",
      "2/3   0.888622\n",
      "2/4   0.293141\n",
      "2/5   0.083983\n",
      "3/4   0.437512\n",
      "3/5   0.151370\n",
      "4/5   0.609278\n"
     ]
    }
   ],
   "source": [
    "for name,val in p_value.items():\n",
    "    if val<0.05:\n",
    "        print(\"%s   %f\" % (name,val))\n",
    "print(\"\\n\\n\\n\")\n",
    "for name,val in p_value.items():\n",
    "    if val>0.05:\n",
    "        print(\"%s   %f\" % (name,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1/2', 0.01219756048790242),\n",
       " ('1/3', 0.030193961207758448),\n",
       " ('2/5', 0.08398320335932813),\n",
       " ('3/5', 0.15136972605478904),\n",
       " ('1/4', 0.21375724855028994),\n",
       " ('2/4', 0.29314137172565485),\n",
       " ('3/4', 0.4375124975004999),\n",
       " ('1/5', 0.5870825834833033),\n",
       " ('4/5', 0.6092781443711258),\n",
       " ('2/3', 0.888622275544891)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for name,val in p_value.items():\n",
    "     dic[name]=val\n",
    "sorted(dic.items(), key=lambda d:d[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94       100\n",
      "         1.0       0.96      0.91      0.93       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.93       200\n",
      "weighted avg       0.94      0.94      0.93       200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.85      0.85       100\n",
      "         1.0       0.85      0.86      0.86       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.86      0.85      0.85       200\n",
      "weighted avg       0.86      0.85      0.85       200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.85      0.86       100\n",
      "         1.0       0.85      0.88      0.87       100\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.87      0.86      0.86       200\n",
      "weighted avg       0.87      0.86      0.86       200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.90       100\n",
      "         1.0       0.91      0.88      0.89       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.89       200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.92      0.92       100\n",
      "         1.0       0.92      0.91      0.91       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.91       200\n",
      "weighted avg       0.92      0.92      0.91       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# errordocs = []\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "model_name=['DBOW','DM/M','DM/S','DBOW+DM/M','DBOW+DM/S']\n",
    "i=0\n",
    "for line in allpreds:\n",
    "#     print(list(map(int,line.predictions)))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(list(map(int,line.sentiment)), list(map(int,line.predictions)))\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='%s (AUC = %0.3f)' % (model_name[i],roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "#     plt.title('Receiver Operating Characteristic for the five systems and their AUC(Area Under the ROC Curve) values')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    i+=1\n",
    "#     print(fpr,tpr)\n",
    "    print(classification_report(line.sentiment, line.predictions))\n",
    "#     for i in range(len(line.sentiment)):\n",
    "        \n",
    "#         if line.predictions[i]!=line.sentiment[i]:\n",
    "#             errordocs.append(i)\n",
    "# print(errordocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_docs=[[26, 52, 64, 86, 107, 113, 120, 128, 134, 138, 180, 183, 184], [19, 22, 26, 27, 34, 35, 46, 52, 55, 62, 71, 74, 86, 89, 95, 107, 120, 132, 134, 138, 153, 162, 169, 182, 183, 184, 191, 193, 195], [18, 19, 22, 24, 25, 27, 34, 46, 52, 55, 58, 62, 74, 86, 89, 107, 117, 120, 134, 138, 153, 169, 182, 183, 184, 191, 193], [25, 26, 52, 55, 62, 71, 74, 76, 86, 107, 113, 120, 130, 134, 138, 149, 180, 182, 183, 184, 193], [19, 26, 34, 52, 62, 74, 83, 86, 107, 113, 120, 134, 138, 149, 180, 182, 183]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 52, 64, 86, 107, 113, 120, 128, 134, 138, 180, 183, 184]\n",
      "[19, 22, 26, 27, 34, 35, 46, 52, 55, 62, 71, 74, 86, 89, 95, 107, 120, 132, 134, 138, 153, 162, 169, 182, 183, 184, 191, 193, 195]\n",
      "[18, 19, 22, 24, 25, 27, 34, 46, 52, 55, 58, 62, 74, 86, 89, 107, 117, 120, 134, 138, 153, 169, 182, 183, 184, 191, 193]\n",
      "[25, 26, 52, 55, 62, 71, 74, 76, 86, 107, 113, 120, 130, 134, 138, 149, 180, 182, 183, 184, 193]\n",
      "[19, 26, 34, 52, 62, 74, 83, 86, 107, 113, 120, 134, 138, 149, 180, 182, 183]\n"
     ]
    }
   ],
   "source": [
    "for line in error_docs:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(52, 5),\n",
       " (86, 5),\n",
       " (107, 5),\n",
       " (120, 5),\n",
       " (134, 5),\n",
       " (138, 5),\n",
       " (183, 5),\n",
       " (26, 4),\n",
       " (184, 4),\n",
       " (62, 4),\n",
       " (74, 4),\n",
       " (182, 4),\n",
       " (113, 3),\n",
       " (180, 3),\n",
       " (19, 3),\n",
       " (34, 3),\n",
       " (55, 3),\n",
       " (193, 3),\n",
       " (22, 2),\n",
       " (27, 2)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(errordocs).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The summer of raunch continues to spread into theatres with this latest yuk fest, filled with sick jokes and teen dialogue aplenty. If you go expecting Dawson\\'s Creek, you\\'re in for a problem. If your expectations are lower (and better, I might add), you will enjoy the hell out of American Pie. The movie casts several unknowns, with the only real recognizable one being SCTV\\'s own Eugene Levy as a happy-go-lucky dad. The story revolves around four high school seniors who have one goal before the school year gets out-get laid. That\\'s pretty much it. Throughout the movie, little sick comic bits are sprinkled throughout, including a memorable scene involving an apple pie (I won\\'t give it away, but you probably know what it is) and an Internet broadcast gone horribly awry. Of course, the movie has some slightly sentimental bits, but they don\\'t drag the movie\\'s humor content down that bad. Most of the actors get their job done, but it\\'s Levy who\\'s a hoot, a father who tries to talk sex with his son with the help of some curious \"visual aids\". I couldn\\'t stop laughing during this movie, and if you can stand all the raunch and the sex references, then American Pie is for you. If you\\'re one of those \"conservative\" types, well, I\\'ll bet you\\'re having fun at home while this, South Park, and Austin Powers II plays in theatres, now aren\\'t you?'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(cv_test_docs[183].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[860]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test_docs[86].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved Sentiment-Prediction Accuracy\n",
    "--------------------------------------\n",
    "Compare error rates achieved, best-to-worst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_rate Model\n",
      "0.065000 Doc2Vec(dbow,d100,n5,mc2,t8)\n",
      "0.085000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8)\n",
      "0.090000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(dm/c,d100,n5,w5,mc2,t8)\n",
      "0.095000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t8)\n",
      "0.105000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.110000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"w2\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.120000 Doc2Vec(dbow,d100,n5,mc2,t8)+Doc2Vec(\"mc5w5\",dm/m,d100,n5,w5,mc5,t8)\n",
      "0.130000 Doc2Vec(\"w2\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.135000 Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8)\n",
      "0.140000 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.145000 Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.160000 Doc2Vec(\"hs=0\",dm/m,d100,n5,hs,w5,mc2,t8)\n",
      "0.160000 Doc2Vec(\"mc5w2\",dm/m,d100,n5,w2,mc2,t8)\n",
      "0.165000 Doc2Vec(\"mc5w5\",dm/m,d100,n5,w5,mc5,t8)\n",
      "0.175000 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t8)\n",
      "0.200000 Doc2Vec(\"alpha=0.025\",dm/m,d100,n5,w10,mc2,t8)\n",
      "0.250000 Doc2Vec(dm/c,d100,n5,w5,mc2,t8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Err_rate Model\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are inferred vectors close to the precalculated ones?\n",
    "-----------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 28066...\n",
      "Doc2Vec(dbow,d100,n5,mc2,t8):\n",
      " [(28066, 0.9800949096679688), (32916, 0.633941650390625), (81052, 0.6129944324493408)]\n",
      "28066\n",
      "Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8):\n",
      " [(28066, 0.9476486444473267), (5994, 0.6039725542068481), (8328, 0.5808252096176147)]\n",
      "28066\n",
      "Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8):\n",
      " [(28066, 0.9541605710983276), (8328, 0.7591161131858826), (12457, 0.7508106231689453)]\n",
      "28066\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # Pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))\n",
    "    print(model.docvecs.most_similar([inferred_docvec], topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = np.zeros(shape=(3,100))\n",
    "mslist = np.zeros(shape=(3,100,3,2))\n",
    "for i in range(100):\n",
    "    doc_id = np.random.randint(simple_models[0].docvecs.count)  # Pick random doc; re-run cell for more examples\n",
    "# print('for doc %d...' % doc_id)\n",
    "    j=0\n",
    "    for model in simple_models:\n",
    "        inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n",
    "        mslist[j][i] = model.docvecs.most_similar([inferred_docvec], topn=3)\n",
    "        if doc_id == model.docvecs.most_similar([inferred_docvec], topn=3)[0][0]:\n",
    "            ms[j][i] = 1\n",
    "        else:\n",
    "            ms[j][i] = 0\n",
    "        j+=1\n",
    "#         print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, here the stored vector from 20 epochs of training is usually one of the\n",
    "closest to a freshly-inferred vector for the same words. Defaults for\n",
    "inference may benefit from tuning for each dataset or model parameters.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do close documents seem more related than distant ones?\n",
    "-------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (74907): ¬´spoofing horror films is something people think is easy. in truth, it isn't. just being stupid doesn't make something funny. it just makes it stupid. throwing a bunch of naked chicks in the flick only makes me think of some porn i'd rather be watching.<br /><br />this is a bad movie that isn't scary. it isn't funny. heck, it isn't even gory. it is boring. i guess that's something.¬ª\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8):\n",
      "\n",
      "MOST (11352, 0.7791767120361328): ¬´Leslie Nielson is a very talented actor, who made a huge mistake by doing this film. It doesn't even come close to being funny. The best word to describe it is STUPID!¬ª\n",
      "\n",
      "MEDIAN (93819, 0.5388213992118835): ¬´Namely, the cinematography is gorgeous, the acting either overblown or wooden, the dialog absurd, and the story - well, the writer should be patted on the head and sent back to school, with the script posted proudly on the refrigerator.<br /><br />What I liked: as I said, the camera-work was marvelous, Delphine Seyrig does a marvelous job as the 'vampire' who wears her heart on her sleeve, and her secretary, played by Andrea Rau, is beautiful, with perhaps the best actual acting in the film. There's plenty of sensual nudity, tastefully done.<br /><br />However, the story leaves many threads dangling, the dialog leaves us wondering why the characters are acting as they are, and the editing is typical for European art films. As my daughter said at one point, \"Okay - the car is driving past the pillars - we get it already!\" The pacing is slow. No, really - it's slow. For most of the movie, you can run out to the kitchen to grab a snack without missing anything of import - it'll give you something to do while you're waiting.<br /><br />The story involves several red herrings - the protagonist's ambiguous relationship with his \"mother\", whom he's intending to spend his honeymoon with, looks to be one of those mysteries that we'll understand in the final reel, but after a very mysterious telephone conversation (in which we learn that \"mother\" is male), it's left to dangle. The concierge and the retired policeman clearly remember the Countess from her visit, 20 years earlier - but that's never fleshed out, either.<br /><br />The newlywed husband snaps and beats his bride with a belt, but his motivation is never clear - is he a sadist, is he in need of anger management training (and what was he angry about?), or is he just desperate for something to happen? The wife leaves, but is stopped at train-side by the Countess. Apparently, by being remarkably pushy while trying to look vulnerable worked in 1971 - perhaps I should have tried that at the singles bars.<br /><br />The ending sequence is awful - the Countess is being driven through a wooded road at night, urging the other survivor from the hotel to drive faster, faster - so they'll get to their destination before daylight, while distracting them with love chat and fondling. Suddenly, the sun is well overhead - amazing, how fast it rises in that part of the world. The crash is almost a relief. How the sole survivor actually survives this gives us one more mystery to contemplate.<br /><br />However, this is an art film, not a Hollywood production - it's much more about mood than story or realistic people. In this light, it works. Were I more fond of \"arty\" films, I'd perhaps have rated this higher.¬ª\n",
      "\n",
      "LEAST (62606, 0.24436722695827484): ¬´Once interested in viewing a script outline or a detailed dialog box inspired by the short s√©ance \"DEL FIORE DI CARTA\", you are kindly requested to refer to the Italian revue ANTEPRIMA, No 5, Sassoferatto , Ancona, Italy, published in January 1998, page 31, where I published the film scenario entitled \"ISMAEL\", with a prologue about Laura Betti's opinion Nicolas Xenios, ISMAEL, Omaggio a Pier Paolo Pazolini, Translated and adapted by Tea Boldrini. The story is about an archetypal three-membered family of the western cultural context , who walk and talk about death in their typical middle class apartment . In parallel, a Guillotine is being prepared in a medieval small town in front of the prison where the leading role, Ismael, is about to be condemned to death by the local judge. The crowd is invited to accomplish the procedure by gathering in front of the prison, where the execution will take place as soon as the flower Narcissus near his prison window will faint. The unexpected fact will be that the prisoner's daughter, after her long prayers to God, will decide to replace the real flower Narcissus near her father's window by a similar paper flower that will, naturally, never faint. The result is that FEAR of the eternity will replace the existentialists fear for DEATH and the prisoner's shadow will purchase him for ever and ever.<br /><br />The text is published in Italian. You are welcomed to read and comment on it my Italian speaking friends. Bye thanks¬ª\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): ¬´%s¬ª\\n' % (doc_id, ' '.join(alldocs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    s = sims[index]\n",
    "    i = sims[index][0]\n",
    "    words = ' '.join(alldocs[i].words)\n",
    "    print(u'%s %s: ¬´%s¬ª\\n' % (label, s, words))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Somewhat, in terms of reviewer tone, movie genre, etc... the MOST\n",
    "cosine-similar docs usually seem more like the TARGET than the MEDIAN or\n",
    "LEAST... especially if the MOST has a cosine-similarity > 0.5. Re-run the\n",
    "cell to try another random target document.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the word vectors show useful similarities?\n",
    "---------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 23:23:27,988 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_word: 'boundless' model: Doc2Vec(dbow,d100,n5,mc2,t8) similar words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 23:23:28,249 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-01-08 23:23:28,378 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1. 0.44 'wife!\".'\n",
      "    2. 0.42 'on-target.'\n",
      "    3. 0.41 'Incoherent'\n",
      "    4. 0.41 'HOLE!!)'\n",
      "    5. 0.41 'hirsute'\n",
      "    6. 0.40 'Cameroons'\n",
      "    7. 0.40 'co-incidence'\n",
      "    8. 0.40 'Zoo,'\n",
      "    9. 0.39 'Operating'\n",
      "    10. 0.39 'done\".'\n",
      "\n",
      "target_word: 'boundless' model: Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8) similar words:\n",
      "    1. 0.56 'perseverance,'\n",
      "    2. 0.55 'blasts,'\n",
      "    3. 0.55 'Danny(Paul'\n",
      "    4. 0.54 'tenderness,'\n",
      "    5. 0.54 'medication.<br'\n",
      "    6. 0.54 'inventiveness,'\n",
      "    7. 0.54 'sadness,'\n",
      "    8. 0.53 'vanity,'\n",
      "    9. 0.53 'innate'\n",
      "    10. 0.52 \"Strudwick's\"\n",
      "\n",
      "target_word: 'boundless' model: Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8) similar words:\n",
      "    1. 0.62 'medication.<br'\n",
      "    2. 0.62 'uncontained'\n",
      "    3. 0.61 'blasts,'\n",
      "    4. 0.60 'tenderness,'\n",
      "    5. 0.59 'perseverance,'\n",
      "    6. 0.58 'unbridled'\n",
      "    7. 0.58 'intuition,'\n",
      "    8. 0.57 'expending'\n",
      "    9. 0.57 'sadness,'\n",
      "    10. 0.56 'anxiety,'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "word_models = simple_models[:]\n",
    "\n",
    "def pick_random_word(model, threshold=10):\n",
    "    # pick a random word with a suitable number of occurences\n",
    "    while True:\n",
    "        word = random.choice(model.wv.index2word)\n",
    "        if model.wv.vocab[word].count > threshold:\n",
    "            return word\n",
    "\n",
    "target_word = pick_random_word(word_models[0])\n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "# target_word = 'comedy/drama'\n",
    "\n",
    "for model in word_models:\n",
    "    print('target_word: %r model: %s similar words:' % (target_word, model))\n",
    "    for i, (word, sim) in enumerate(model.wv.most_similar(target_word, topn=10), 1):\n",
    "        print('    %d. %.2f %r' % (i, sim, word))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the word vectors from this dataset any good at analogies?\n",
    "-------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success, questions-words.txt is available for next steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 23:24:04,765 : INFO : Evaluating word analogies for top 300000 words in the model on questions-words.txt\n",
      "2020-01-08 23:24:06,780 : INFO : capital-common-countries: 0.0% (0/420)\n",
      "2020-01-08 23:24:11,109 : INFO : capital-world: 0.0% (0/902)\n",
      "2020-01-08 23:24:11,526 : INFO : currency: 0.0% (0/86)\n",
      "2020-01-08 23:24:18,709 : INFO : city-in-state: 0.0% (0/1510)\n",
      "2020-01-08 23:24:21,104 : INFO : family: 0.0% (0/506)\n",
      "2020-01-08 23:24:25,811 : INFO : gram1-adjective-to-adverb: 0.0% (0/992)\n",
      "2020-01-08 23:24:29,436 : INFO : gram2-opposite: 0.0% (0/756)\n",
      "2020-01-08 23:24:35,653 : INFO : gram3-comparative: 0.0% (0/1332)\n",
      "2020-01-08 23:24:40,648 : INFO : gram4-superlative: 0.0% (0/1056)\n",
      "2020-01-08 23:24:45,347 : INFO : gram5-present-participle: 0.0% (0/992)\n",
      "2020-01-08 23:24:52,217 : INFO : gram6-nationality-adjective: 0.0% (0/1445)\n",
      "2020-01-08 23:24:59,508 : INFO : gram7-past-tense: 0.0% (0/1560)\n",
      "2020-01-08 23:25:05,103 : INFO : gram8-plural: 0.0% (0/1190)\n",
      "2020-01-08 23:25:09,201 : INFO : gram9-plural-verbs: 0.0% (0/870)\n",
      "2020-01-08 23:25:09,202 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2020-01-08 23:25:09,202 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2020-01-08 23:25:09,203 : INFO : Total accuracy: 0.0% (0/13617)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t8): 0.00% correct (0 of 13617)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 23:25:09,554 : INFO : Evaluating word analogies for top 300000 words in the model on questions-words.txt\n",
      "2020-01-08 23:25:11,877 : INFO : capital-common-countries: 1.7% (7/420)\n",
      "2020-01-08 23:25:17,371 : INFO : capital-world: 0.3% (3/902)\n",
      "2020-01-08 23:25:17,931 : INFO : currency: 0.0% (0/86)\n",
      "2020-01-08 23:25:25,958 : INFO : city-in-state: 0.1% (2/1510)\n",
      "2020-01-08 23:25:28,970 : INFO : family: 37.5% (190/506)\n",
      "2020-01-08 23:25:34,695 : INFO : gram1-adjective-to-adverb: 3.7% (37/992)\n",
      "2020-01-08 23:25:39,000 : INFO : gram2-opposite: 6.7% (51/756)\n",
      "2020-01-08 23:25:46,477 : INFO : gram3-comparative: 46.4% (618/1332)\n",
      "2020-01-08 23:25:52,777 : INFO : gram4-superlative: 31.3% (331/1056)\n",
      "2020-01-08 23:25:58,434 : INFO : gram5-present-participle: 23.1% (229/992)\n",
      "2020-01-08 23:26:06,485 : INFO : gram6-nationality-adjective: 3.7% (53/1445)\n",
      "2020-01-08 23:26:15,679 : INFO : gram7-past-tense: 23.8% (372/1560)\n",
      "2020-01-08 23:26:22,767 : INFO : gram8-plural: 16.3% (194/1190)\n",
      "2020-01-08 23:26:27,862 : INFO : gram9-plural-verbs: 39.8% (346/870)\n",
      "2020-01-08 23:26:27,863 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2020-01-08 23:26:27,864 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2020-01-08 23:26:27,864 : INFO : Total accuracy: 17.9% (2433/13617)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"mean\",dm/m,d100,n5,w2,mc2,t8): 17.87% correct (2433 of 13617)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-08 23:26:28,743 : INFO : Evaluating word analogies for top 300000 words in the model on questions-words.txt\n",
      "2020-01-08 23:26:30,910 : INFO : capital-common-countries: 1.9% (8/420)\n",
      "2020-01-08 23:26:35,618 : INFO : capital-world: 0.7% (6/902)\n",
      "2020-01-08 23:26:36,098 : INFO : currency: 0.0% (0/86)\n",
      "2020-01-08 23:26:44,068 : INFO : city-in-state: 0.3% (4/1510)\n",
      "2020-01-08 23:26:46,971 : INFO : family: 36.8% (186/506)\n",
      "2020-01-08 23:26:52,423 : INFO : gram1-adjective-to-adverb: 5.4% (54/992)\n",
      "2020-01-08 23:26:56,793 : INFO : gram2-opposite: 5.4% (41/756)\n",
      "2020-01-08 23:27:06,094 : INFO : gram3-comparative: 46.5% (620/1332)\n",
      "2020-01-08 23:27:12,559 : INFO : gram4-superlative: 34.7% (366/1056)\n",
      "2020-01-08 23:27:18,883 : INFO : gram5-present-participle: 26.6% (264/992)\n",
      "2020-01-08 23:27:27,190 : INFO : gram6-nationality-adjective: 2.8% (41/1445)\n",
      "2020-01-08 23:27:36,171 : INFO : gram7-past-tense: 19.4% (303/1560)\n",
      "2020-01-08 23:27:43,199 : INFO : gram8-plural: 14.2% (169/1190)\n",
      "2020-01-08 23:27:48,705 : INFO : gram9-plural-verbs: 43.6% (379/870)\n",
      "2020-01-08 23:27:48,706 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2020-01-08 23:27:48,707 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2020-01-08 23:27:48,708 : INFO : Total accuracy: 17.9% (2441/13617)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(\"sum\",dm/s,d100,n5,w2,mc2,t8): 17.93% correct (2441 of 13617)\n"
     ]
    }
   ],
   "source": [
    "# grab the file if not already local\n",
    "questions_filename = 'questions-words.txt'\n",
    "if not os.path.isfile(questions_filename):\n",
    "    # Download IMDB archive\n",
    "    print(\"Downloading analogy questions file...\")\n",
    "    url = u'https://raw.githubusercontent.com/tmikolov/word2vec/master/questions-words.txt'\n",
    "    with smart_open.open(url, 'rb') as fin:\n",
    "        with smart_open.open(questions_filename, 'wb') as fout:\n",
    "            fout.write(fin.read())\n",
    "assert os.path.isfile(questions_filename), \"questions-words.txt unavailable\"\n",
    "print(\"Success, questions-words.txt is available for next steps.\")\n",
    "\n",
    "# Note: this analysis takes many minutes\n",
    "for model in word_models:\n",
    "    score, sections = model.wv.evaluate_word_analogies('questions-words.txt')\n",
    "    correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n",
    "    print('%s: %0.2f%% correct (%d of %d)' % (model, float(correct*100)/(correct+incorrect), correct, correct+incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
